{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = util.load_openstax_course('University Physics Volume 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>learning_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find the order of magnitude of the following p...</td>\n",
       "      <td>Describe the scope of physics.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Find the order of magnitude of the following p...</td>\n",
       "      <td>Calculate the order of magnitude of a quantity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find the order of magnitude of the following p...</td>\n",
       "      <td>Compare measurable length, mass, and timescale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Find the order of magnitude of the following p...</td>\n",
       "      <td>Describe the relationships among models, theor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Use the orders of magnitude you found in the p...</td>\n",
       "      <td>Describe the scope of physics.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Find the order of magnitude of the following p...   \n",
       "1  Find the order of magnitude of the following p...   \n",
       "2  Find the order of magnitude of the following p...   \n",
       "3  Find the order of magnitude of the following p...   \n",
       "4  Use the orders of magnitude you found in the p...   \n",
       "\n",
       "                                       learning_goal  \n",
       "0                     Describe the scope of physics.  \n",
       "1    Calculate the order of magnitude of a quantity.  \n",
       "2  Compare measurable length, mass, and timescale...  \n",
       "3  Describe the relationships among models, theor...  \n",
       "4                     Describe the scope of physics.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['learning_goal'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['question'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('question')['learning_goal'].agg(list).value_counts().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define what a task is \n",
    "2. (small) Debug code so that it loads Chemistry 2e\n",
    "3. (ambitious) Try a simple finetuning baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Preprcoessing data\n",
    " - (for Principles of Chemistry) stem the verb of the learning goal\n",
    " - Unicode characters:\n",
    "    - delta --> \"delta\"\n",
    "    - exponents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_shot_sample(data, learning_goal, match=True, k=5):\n",
    "  if match:\n",
    "    sample_data = data[data['learning_goal'] == learning_goal]\n",
    "  else:\n",
    "    sample_data = data[data['learning_goal'] != learning_goal]\n",
    "  return sample_data.sample(n=min(k, len(sample_data)))\n",
    "  \n",
    "  \n",
    "def meta_task(data, k=5):\n",
    "  # very clunky, but only look at data whose learning goals have enough examples\n",
    "  data = data[data['learning_goal'].isin(\n",
    "      data['learning_goal'].value_counts()[data['learning_goal'].value_counts() >= k].index\n",
    "  )]\n",
    "  query = np.random.choice(data['question'].unique())\n",
    "  learning_goal = data[data['question'] == query]['learning_goal'].sample().values[0]\n",
    "  k_shot_true = k_shot_sample(data[data['question'] != query], learning_goal, match=True, k=k)\n",
    "  k_shot_false = k_shot_sample(data[data['question'] != query], learning_goal, match=False, k=k)\n",
    "  return k_shot_true, k_shot_false, query, learning_goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_table_of_contents(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    chapter_names = [\n",
    "        line for line in lines \n",
    "        if re.match('[0-9]+\\.[0-9]+', line)\n",
    "    ]\n",
    "    return chapter_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def scrape_learning_goals(url):\n",
    "    response = urllib.request.urlopen(url)\n",
    "    html = response.read().decode('utf8')\n",
    "    objectives_list = re.findall('<ul id=\\\"list-00001\\\">[\\s\\S]*?</ul>', html)\n",
    "    if len(objectives_list) == 0:\n",
    "        print('faulty:', url)\n",
    "        return []\n",
    "    learning_objectives = re.findall('<li>[\\s\\S].*</li>', objectives_list[0])\n",
    "    return [item[4:-5] for item in learning_objectives]\n",
    "\n",
    "def clean_url_extension(chapter_name):\n",
    "    return chapter_name.lower().replace(',', '').replace(':', '').replace(' ', '-').replace('.', '-')\n",
    "    \n",
    "\n",
    "def read_learning_goals(chapter_names, base_url):\n",
    "    learning_goals = {}\n",
    "    for chapter in chapter_names:\n",
    "        url = base_url + clean_url_extension(chapter)\n",
    "        print(url)\n",
    "        learning_goals[chapter] = scrape_learning_goals(url)\n",
    "    return learning_goals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openstax.org/books/chemistry-2e/pages/1-1-chemistry-in-context\n",
      "https://openstax.org/books/chemistry-2e/pages/1-2-phases-and-classification-of-matter\n",
      "https://openstax.org/books/chemistry-2e/pages/1-3-physical-and-chemical-properties\n",
      "https://openstax.org/books/chemistry-2e/pages/1-4-measurements\n",
      "https://openstax.org/books/chemistry-2e/pages/1-5-measurement-uncertainty-accuracy-and-precision\n",
      "https://openstax.org/books/chemistry-2e/pages/1-6-mathematical-treatment-of-measurement-results\n",
      "https://openstax.org/books/chemistry-2e/pages/2-1-early-ideas-in-atomic-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/2-2-evolution-of-atomic-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/2-3-atomic-structure-and-symbolism\n",
      "https://openstax.org/books/chemistry-2e/pages/2-4-chemical-formulas\n",
      "https://openstax.org/books/chemistry-2e/pages/2-5-the-periodic-table\n",
      "https://openstax.org/books/chemistry-2e/pages/2-6-ionic-and-molecular-compounds\n",
      "https://openstax.org/books/chemistry-2e/pages/2-7-chemical-nomenclature\n",
      "https://openstax.org/books/chemistry-2e/pages/3-1-formula-mass-and-the-mole-concept\n",
      "https://openstax.org/books/chemistry-2e/pages/3-2-determining-empirical-and-molecular-formulas\n",
      "https://openstax.org/books/chemistry-2e/pages/3-3-molarity\n",
      "https://openstax.org/books/chemistry-2e/pages/3-4-other-units-for-solution-concentrations\n",
      "https://openstax.org/books/chemistry-2e/pages/4-1-writing-and-balancing-chemical-equations\n",
      "https://openstax.org/books/chemistry-2e/pages/4-2-classifying-chemical-reactions\n",
      "https://openstax.org/books/chemistry-2e/pages/4-3-reaction-stoichiometry\n",
      "https://openstax.org/books/chemistry-2e/pages/4-4-reaction-yields\n",
      "https://openstax.org/books/chemistry-2e/pages/4-5-quantitative-chemical-analysis\n",
      "https://openstax.org/books/chemistry-2e/pages/5-1-energy-basics\n",
      "https://openstax.org/books/chemistry-2e/pages/5-2-calorimetry\n",
      "https://openstax.org/books/chemistry-2e/pages/5-3-enthalpy\n",
      "https://openstax.org/books/chemistry-2e/pages/6-1-electromagnetic-energy\n",
      "https://openstax.org/books/chemistry-2e/pages/6-2-the-bohr-model\n",
      "https://openstax.org/books/chemistry-2e/pages/6-3-development-of-quantum-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/6-4-electronic-structure-of-atoms-electron-configurations\n",
      "https://openstax.org/books/chemistry-2e/pages/6-5-periodic-variations-in-element-properties\n",
      "https://openstax.org/books/chemistry-2e/pages/7-1-ionic-bonding\n",
      "https://openstax.org/books/chemistry-2e/pages/7-2-covalent-bonding\n",
      "https://openstax.org/books/chemistry-2e/pages/7-3-lewis-symbols-and-structures\n",
      "https://openstax.org/books/chemistry-2e/pages/7-4-formal-charges-and-resonance\n",
      "https://openstax.org/books/chemistry-2e/pages/7-5-strengths-of-ionic-and-covalent-bonds\n",
      "https://openstax.org/books/chemistry-2e/pages/7-6-molecular-structure-and-polarity\n",
      "https://openstax.org/books/chemistry-2e/pages/8-1-valence-bond-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/8-2-hybrid-atomic-orbitals\n",
      "https://openstax.org/books/chemistry-2e/pages/8-3-multiple-bonds\n",
      "https://openstax.org/books/chemistry-2e/pages/8-4-molecular-orbital-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/9-1-gas-pressure\n",
      "https://openstax.org/books/chemistry-2e/pages/9-2-relating-pressure-volume-amount-and-temperature-the-ideal-gas-law\n",
      "https://openstax.org/books/chemistry-2e/pages/9-3-stoichiometry-of-gaseous-substances-mixtures-and-reactions\n",
      "https://openstax.org/books/chemistry-2e/pages/9-4-effusion-and-diffusion-of-gases\n",
      "https://openstax.org/books/chemistry-2e/pages/9-5-the-kinetic-molecular-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/9-6-non-ideal-gas-behavior\n",
      "https://openstax.org/books/chemistry-2e/pages/10-1-intermolecular-forces\n",
      "https://openstax.org/books/chemistry-2e/pages/10-2-properties-of-liquids\n",
      "https://openstax.org/books/chemistry-2e/pages/10-3-phase-transitions\n",
      "https://openstax.org/books/chemistry-2e/pages/10-4-phase-diagrams\n",
      "https://openstax.org/books/chemistry-2e/pages/10-5-the-solid-state-of-matter\n",
      "https://openstax.org/books/chemistry-2e/pages/10-6-lattice-structures-in-crystalline-solids\n",
      "https://openstax.org/books/chemistry-2e/pages/11-1-the-dissolution-process\n",
      "https://openstax.org/books/chemistry-2e/pages/11-2-electrolytes\n",
      "https://openstax.org/books/chemistry-2e/pages/11-3-solubility\n",
      "https://openstax.org/books/chemistry-2e/pages/11-4-colligative-properties\n",
      "https://openstax.org/books/chemistry-2e/pages/11-5-colloids\n",
      "https://openstax.org/books/chemistry-2e/pages/12-1-chemical-reaction-rates\n",
      "https://openstax.org/books/chemistry-2e/pages/12-2-factors-affecting-reaction-rates\n",
      "https://openstax.org/books/chemistry-2e/pages/12-3-rate-laws\n",
      "https://openstax.org/books/chemistry-2e/pages/12-4-integrated-rate-laws\n",
      "https://openstax.org/books/chemistry-2e/pages/12-5-collision-theory\n",
      "https://openstax.org/books/chemistry-2e/pages/12-6-reaction-mechanisms\n",
      "https://openstax.org/books/chemistry-2e/pages/12-7-catalysis\n",
      "https://openstax.org/books/chemistry-2e/pages/13-1-chemical-equilibria\n",
      "https://openstax.org/books/chemistry-2e/pages/13-2-equilibrium-constants\n",
      "https://openstax.org/books/chemistry-2e/pages/13-3-shifting-equilibria-le-chateliers-principle\n",
      "https://openstax.org/books/chemistry-2e/pages/13-4-equilibrium-calculations\n",
      "https://openstax.org/books/chemistry-2e/pages/14-1-bronsted-lowry-acids-and-bases\n",
      "https://openstax.org/books/chemistry-2e/pages/14-2-ph-and-poh\n",
      "https://openstax.org/books/chemistry-2e/pages/14-3-relative-strengths-of-acids-and-bases\n",
      "https://openstax.org/books/chemistry-2e/pages/14-4-hydrolysis-of-salts\n",
      "https://openstax.org/books/chemistry-2e/pages/14-5-polyprotic-acids\n",
      "https://openstax.org/books/chemistry-2e/pages/14-6-buffers\n",
      "https://openstax.org/books/chemistry-2e/pages/14-7-acid-base-titrations\n",
      "https://openstax.org/books/chemistry-2e/pages/15-1-precipitation-and-dissolution\n",
      "https://openstax.org/books/chemistry-2e/pages/15-2-lewis-acids-and-bases\n",
      "https://openstax.org/books/chemistry-2e/pages/15-3-coupled-equilibria\n",
      "https://openstax.org/books/chemistry-2e/pages/16-1-spontaneity\n",
      "https://openstax.org/books/chemistry-2e/pages/16-2-entropy\n",
      "https://openstax.org/books/chemistry-2e/pages/16-3-the-second-and-third-laws-of-thermodynamics\n",
      "https://openstax.org/books/chemistry-2e/pages/16-4-free-energy\n",
      "https://openstax.org/books/chemistry-2e/pages/17-1-review-of-redox-chemistry\n",
      "https://openstax.org/books/chemistry-2e/pages/17-2-galvanic-cells\n",
      "https://openstax.org/books/chemistry-2e/pages/17-3-electrode-and-cell-potentials\n",
      "https://openstax.org/books/chemistry-2e/pages/17-4-potential-free-energy-and-equilibrium\n",
      "https://openstax.org/books/chemistry-2e/pages/17-5-batteries-and-fuel-cells\n",
      "https://openstax.org/books/chemistry-2e/pages/17-6-corrosion\n",
      "https://openstax.org/books/chemistry-2e/pages/17-7-electrolysis\n",
      "https://openstax.org/books/chemistry-2e/pages/18-1-periodicity\n",
      "https://openstax.org/books/chemistry-2e/pages/18-2-occurrence-and-preparation-of-the-representative-metals\n",
      "https://openstax.org/books/chemistry-2e/pages/18-3-structure-and-general-properties-of-the-metalloids\n",
      "https://openstax.org/books/chemistry-2e/pages/18-4-structure-and-general-properties-of-the-nonmetals\n",
      "https://openstax.org/books/chemistry-2e/pages/18-5-occurrence-preparation-and-compounds-of-hydrogen\n",
      "https://openstax.org/books/chemistry-2e/pages/18-6-occurrence-preparation-and-properties-of-carbonates\n",
      "https://openstax.org/books/chemistry-2e/pages/18-7-occurrence-preparation-and-properties-of-nitrogen\n",
      "https://openstax.org/books/chemistry-2e/pages/18-8-occurrence-preparation-and-properties-of-phosphorus\n",
      "https://openstax.org/books/chemistry-2e/pages/18-9-occurrence-preparation-and-compounds-of-oxygen\n",
      "https://openstax.org/books/chemistry-2e/pages/18-10-occurrence-preparation-and-properties-of-sulfur\n",
      "https://openstax.org/books/chemistry-2e/pages/18-11-occurrence-preparation-and-properties-of-halogens\n",
      "https://openstax.org/books/chemistry-2e/pages/18-12-occurrence-preparation-and-properties-of-the-noble-gases\n",
      "https://openstax.org/books/chemistry-2e/pages/19-1-occurrence-preparation-and-properties-of-transition-metals-and-their-compounds\n",
      "faulty: https://openstax.org/books/chemistry-2e/pages/19-1-occurrence-preparation-and-properties-of-transition-metals-and-their-compounds\n",
      "https://openstax.org/books/chemistry-2e/pages/19-2-coordination-chemistry-of-transition-metals\n",
      "https://openstax.org/books/chemistry-2e/pages/19-3-spectroscopic-and-magnetic-properties-of-coordination-compounds\n",
      "https://openstax.org/books/chemistry-2e/pages/20-1-hydrocarbons\n",
      "https://openstax.org/books/chemistry-2e/pages/20-2-alcohols-and-ethers\n",
      "https://openstax.org/books/chemistry-2e/pages/20-3-aldehydes-ketones-carboxylic-acids-and-esters\n",
      "https://openstax.org/books/chemistry-2e/pages/20-4-amines-and-amides\n",
      "https://openstax.org/books/chemistry-2e/pages/21-1-nuclear-structure-and-stability\n",
      "https://openstax.org/books/chemistry-2e/pages/21-2-nuclear-equations\n",
      "https://openstax.org/books/chemistry-2e/pages/21-3-radioactive-decay\n",
      "https://openstax.org/books/chemistry-2e/pages/21-4-transmutation-and-nuclear-energy\n",
      "https://openstax.org/books/chemistry-2e/pages/21-5-uses-of-radioisotopes\n",
      "https://openstax.org/books/chemistry-2e/pages/21-6-biological-effects-of-radiation\n"
     ]
    }
   ],
   "source": [
    "chapter_names = parse_table_of_contents('chemistry2e_table_of_contents.txt')\n",
    "base_url = 'https://openstax.org/books/chemistry-2e/pages/'\n",
    "\n",
    "learning_goals = read_learning_goals(chapter_names, base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('chemistry2e_subchapter_to_learning_goal.json', 'w+') as f:\n",
    "    json.dump(learning_goals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def parse_openstax_questions_file(filename, folder_path):\n",
    "    with open(os.path.join(folder_path, filename), encoding='utf-8') as f:\n",
    "        lines = [l.strip() for l in f]\n",
    "\n",
    "    questions = {}\n",
    "    question_nums = []\n",
    "    current_subchapter = ''\n",
    "    for line in lines:\n",
    "        # when we encounter subchapter heading\n",
    "        subchapter_num = re.match('[0-9]+\\.[0-9]+', line)\n",
    "        if subchapter_num:\n",
    "            current_subchapter = subchapter_num.group(0)\n",
    "            questions[current_subchapter] = []\n",
    "            continue\n",
    "\n",
    "        # when we encounter questions\n",
    "        question_num = re.match('[0-9]+\\. ', line)\n",
    "        if question_num:\n",
    "            question_num = question_num.group(0)\n",
    "            questions[current_subchapter].append(line[len(question_num):])\n",
    "            question_nums.append(question_num)\n",
    "            continue\n",
    "\n",
    "        # if this is part of a previous question\n",
    "        questions[current_subchapter][-1] += '\\n' + line\n",
    "\n",
    "    return questions, question_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, question_nums = parse_openstax_questions_file('Chemistry2e_11.txt', 'OpenStax Dataset/Chemistry 2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_nums = [int(q[:q.find('.')]) for q in question_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_openstax_questions_folder(folder_path):\n",
    "    questions, question_nums = {}, []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('txt'):\n",
    "            q, q_num = parse_openstax_questions_file(filename, folder_path)\n",
    "            questions.update(q)\n",
    "            question_nums.extend(q_num)\n",
    "    return questions, question_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "OPENSTAX_DIR = 'OpenStax Dataset'\n",
    "\n",
    "def load_openstax_course(course_name):\n",
    "    course_code = course_name.replace(' ', '').lower()\n",
    "    with open(f'{course_code}_subchapter_to_learning_goal.json') as f:\n",
    "        subchapter_to_lgs = json.load(f)\n",
    "    \n",
    "    subchapter_to_lgs = {\n",
    "        re.findall('[0-9]+\\.[0-9]+', k)[0]: v for k, v in subchapter_to_lgs.items()\n",
    "    }\n",
    "\n",
    "    questions, question_nums = parse_openstax_questions_folder(\n",
    "        os.path.join(OPENSTAX_DIR, course_name)\n",
    "    )\n",
    "\n",
    "    dataset = []\n",
    "    for subchapter, question_list in questions.items():\n",
    "        for question in question_list:\n",
    "            for learnning_goal in subchapter_to_lgs[subchapter]:\n",
    "                dataset.append([question, learnning_goal])\n",
    "\n",
    "    dataset = pd.DataFrame(data=dataset, columns=['question', 'learning_goal'])\n",
    "    dataset['course'] = course_name\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_openstax_course('University Physics Volume 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d['question'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d['learning_goal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base = 'OpenStax Dataset/Chemistry 2e'\n",
    "for filename in os.listdir(base):\n",
    "    if filename.endswith('txt'):\n",
    "        os.rename(os.path.join(base, filename), os.path.join(base, filename[len('Chemistry2e_'):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "COURSES = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1', \n",
    "    'University Physics Volume 2', \n",
    "    'University Physics Volume 3'\n",
    "]\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in COURSES\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Evaluate the net force on a current loop in an external magnetic field',\n",
       " 'Evaluate the net torque on a current loop in an external magnetic field',\n",
       " 'Define the magnetic dipole moment of a current loop']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgs = data.groupby('question').agg(list).iloc[0]['learning_goal']\n",
    "lgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openstax_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing ProtoBert: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ProtoBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ProtoBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from models.protobert import ProtoBert\n",
    "model = ProtoBert.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = openstax_dataset.get_openstax_dataloader(\n",
    "    'train',\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    100,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "eval_dataloader = openstax_dataset.get_openstax_dataloader(\n",
    "    'val',\n",
    "    4,\n",
    "    2,\n",
    "    2,\n",
    "    100,\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = openstax_dataset.OpenstaxDataset(num_support=2, num_query=2, tokenizer=None)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:05, ?it/s] 0%|          | 0/1000 [00:00<?, ?it/s]\n",
      "Epoch 1 of 1000:   0%|          | 0/1000 [00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.55 GiB already allocated; 3.05 MiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit()\n",
      "File \u001b[1;32mc:\\Users\\amirz\\Source\\smartstem\\smartstem-ai\\trainer.py:111\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader, start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39mas\u001b[39;00m train_bar:\n\u001b[0;32m    109\u001b[0m     \u001b[39mfor\u001b[39;00m batch_num, batch \u001b[39min\u001b[39;00m train_bar:\n\u001b[1;32m--> 111\u001b[0m         outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n\u001b[0;32m    113\u001b[0m         err \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m    115\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    116\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mreduction \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\Source\\smartstem\\smartstem-ai\\models\\protobert.py:70\u001b[0m, in \u001b[0;36mProtoBert.forward\u001b[1;34m(self, task_batch, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m     62\u001b[0m support_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(\n\u001b[0;32m     63\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m     64\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m     65\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m     66\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msupport\n\u001b[0;32m     67\u001b[0m )[\u001b[39m1\u001b[39m]\n\u001b[0;32m     69\u001b[0m \u001b[39m# (nq, dim)\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m query_representations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert(\n\u001b[0;32m     71\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[0;32m     72\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[0;32m     73\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m     74\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mquery\n\u001b[0;32m     75\u001b[0m )[\u001b[39m1\u001b[39m]\n\u001b[0;32m     77\u001b[0m \u001b[39m# (n, dim)\u001b[39;00m\n\u001b[0;32m     78\u001b[0m prototypes \u001b[39m=\u001b[39m support_representations\u001b[39m.\u001b[39mview(n, k, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1015\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[1;32m-> 1022\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1025\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1026\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1027\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1028\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1029\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1030\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1031\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:611\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    602\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    603\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    604\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    609\u001b[0m     )\n\u001b[0;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 611\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m    612\u001b[0m         hidden_states,\n\u001b[0;32m    613\u001b[0m         attention_mask,\n\u001b[0;32m    614\u001b[0m         layer_head_mask,\n\u001b[0;32m    615\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    616\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    617\u001b[0m         past_key_value,\n\u001b[0;32m    618\u001b[0m         output_attentions,\n\u001b[0;32m    619\u001b[0m     )\n\u001b[0;32m    621\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    622\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    487\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    494\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m    495\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 497\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[0;32m    498\u001b[0m         hidden_states,\n\u001b[0;32m    499\u001b[0m         attention_mask,\n\u001b[0;32m    500\u001b[0m         head_mask,\n\u001b[0;32m    501\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    502\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    503\u001b[0m     )\n\u001b[0;32m    504\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    506\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    418\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    419\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    425\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    426\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m--> 427\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[0;32m    428\u001b[0m         hidden_states,\n\u001b[0;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m    430\u001b[0m         head_mask,\n\u001b[0;32m    431\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    432\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    433\u001b[0m         past_key_value,\n\u001b[0;32m    434\u001b[0m         output_attentions,\n\u001b[0;32m    435\u001b[0m     )\n\u001b[0;32m    436\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[0;32m    437\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:316\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     key_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey(hidden_states))\n\u001b[1;32m--> 316\u001b[0m     value_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue(hidden_states))\n\u001b[0;32m    318\u001b[0m query_layer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranspose_for_scores(mixed_query_layer)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_decoder:\n\u001b[0;32m    321\u001b[0m     \u001b[39m# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39m# Further calls to cross_attention layer can then reuse all cross-attention\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[39m# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)\u001b[39;00m\n\u001b[0;32m    327\u001b[0m     \u001b[39m# if encoder bi-directional self-attention `past_key_value` is always `None`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 2.55 GiB already allocated; 3.05 MiB free; 2.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir='outputs', evaluation_strategy='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=openstax_dataset.OpenstaxDataset(tokenizer, 5, 5, True, 128),\n",
    "    eval_dataset=openstax_dataset.OpenstaxDataset(tokenizer, 5, 5, True, 128),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "courses = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1', \n",
    "    'University Physics Volume 2', \n",
    "    'University Physics Volume 3'\n",
    "]\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in courses\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_q = data.groupby('question').agg(list)\n",
    "data_by_lg = data.groupby('learning_goal').agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    [In Figure 14.12, =12V, L=20mH, and R=5.0. D...\n",
       "course      [University Physics Volume 2, University Physi...\n",
       "Name: Analyze circuits that have an inductor and resistor in series, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_group = data_by_lg.iloc[1]\n",
    "lg_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\.conda\\envs\\interchange\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openstax_dataset\n",
    "\n",
    "dataset = openstax_dataset.OpenstaxDataset(\n",
    "    tokenizer=None,\n",
    "    num_support=5,\n",
    "    num_query=2,\n",
    "    tokenize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(10)\n",
    "b = range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "indices = np.array(list(itertools.product(a, b)))\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[np.random.choice(indices.shape[0], replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from trainer import ProtoNet\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "model = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "protonet = ProtoNet(model, 0.0001, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstax_dataset import OpenstaxDataset\n",
    "\n",
    "dataset = OpenstaxDataset(num_support=5, num_query=3, tokenizer=tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "COURSES = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1',\n",
    "    'University Physics Volume 2',\n",
    "    'University Physics Volume 3',\n",
    "]\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in COURSES\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_by_lg = data.groupby('learning_goal').agg(list)\n",
    "data_by_lg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4170"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstax_dataset import OpenstaxDataset\n",
    "\n",
    "k = 5\n",
    "q = 1\n",
    "\n",
    "dataset = OpenstaxDataset(k, q, tokenizer, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in dataset:\n",
    "    break\n",
    "\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('learning_goal').agg(list)['question'].apply(len).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = rng.choice([1, 2, 3, 4], replace=False)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tokenize(x):\n",
    "    return tokenizer(\n",
    "        x,\n",
    "        return_tensors='pt',\n",
    "        max_length=128,\n",
    "        add_special_tokens=True,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tasks = []\n",
    "num_support = 5\n",
    "num_query = 1\n",
    "\n",
    "data_by_lg = data.groupby('learning_goal').agg(list)\n",
    "data_by_question = data.groupby('question').agg(list)\n",
    "\n",
    "for learning_goal in data['learning_goal'].unique():\n",
    "    # select examples that match the sampled learning goal\n",
    "    examples_1 = data_by_lg.loc[learning_goal].question\n",
    "    support_1 = np.random.default_rng(seed=0).choice(examples_1, num_support)\n",
    "    # query_1 = np.random.default_rng(seed=0).choice(examples_1, num_query)\n",
    "\n",
    "    # select examples that do not have this learning goal\n",
    "    examples_0 = data_by_question.drop(examples_1).index\n",
    "    support_0 = np.random.default_rng(seed=0).choice(examples_0, num_support)\n",
    "    # query_0 = np.random.default_rng(seed=0).choice(examples_0, num_query)\n",
    "\n",
    "    support = list(support_0) + list(support_1)\n",
    "    query = [question]\n",
    "    labels_support = ([0] * num_support) + ([1] * num_support)\n",
    "    labels_query = [int(question in examples_1)]\n",
    "\n",
    "    if tokenizer:\n",
    "        support, query = _tokenize(support), _tokenize(query)\n",
    "    labels_support, labels_query = torch.tensor(labels_support), torch.tensor(labels_query)\n",
    "\n",
    "    tasks.append((support, labels_support, query, labels_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_length = [len(tokenizer(q)['input_ids']) for q in data['question'].unique()]\n",
    "max(tokenized_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tokenizer(question)\n",
    "len(x['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = protonet._predict(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_query = torch.stack([task[-1] for task in tasks])\n",
    "labels_query[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(107, device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstax_dataset import OpenstaxTestDataset\n",
    "\n",
    "test_dataset = OpenstaxTestDataset(\n",
    "    course_name='Chemistry 2e',\n",
    "    num_support=5,\n",
    "    num_query=5,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset, sampler, dataloader\n",
    "\n",
    "class SmallDataset(dataset.Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "        super().__init__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return index #self.rng.choice([1, 2, 3, 4])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return 10\n",
    "\n",
    "\n",
    "class SmallSampler(sampler.Sampler):\n",
    "    def __init__(self, data_source=None) -> None:\n",
    "        super().__init__(data_source)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return (i for i in range(5))\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return 5\n",
    "\n",
    "dataloader = dataloader.DataLoader(\n",
    "    dataset=SmallDataset(),\n",
    "    batch_size=1,\n",
    "    sampler=SmallSampler(),\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "OPENSTAX_COURSES = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1', \n",
    "    'University Physics Volume 2', \n",
    "    'University Physics Volume 3'\n",
    "]\n",
    "\n",
    "PRINCIPLES_OF_CHEMISTRY_COURSE = 'Principles of Chemistry 3rd edition'\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in OPENSTAX_COURSES\n",
    "] + [util.load_principles_of_chemistry_course(PRINCIPLES_OF_CHEMISTRY_COURSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>learning_goal</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Outline the historical development of chemistry</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Provide examples of the importance of chemistr...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Describe the scientific method</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Differentiate among hypotheses, theories, and ...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Provide examples illustrating macroscopic, mic...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Explain how you could experimentally determine...   \n",
       "1  Explain how you could experimentally determine...   \n",
       "2  Explain how you could experimentally determine...   \n",
       "3  Explain how you could experimentally determine...   \n",
       "4  Explain how you could experimentally determine...   \n",
       "\n",
       "                                       learning_goal        course  \n",
       "0    Outline the historical development of chemistry  Chemistry 2e  \n",
       "1  Provide examples of the importance of chemistr...  Chemistry 2e  \n",
       "2                     Describe the scientific method  Chemistry 2e  \n",
       "3  Differentiate among hypotheses, theories, and ...  Chemistry 2e  \n",
       "4  Provide examples illustrating macroscopic, mic...  Chemistry 2e  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875, 1267)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = data['question'].unique()\n",
    "learning_goals = data['learning_goal'].unique()\n",
    "len(questions), len(learning_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outline the historical development of chemistry'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_goal = learning_goals[0]\n",
    "learning_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "OPENAI_API_TOKEN = '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'\n",
    "openai.api_key = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for lg in learning_goals:\n",
    "    response = openai.Embedding.create(\n",
    "        input=lg,\n",
    "        model=\"text-similarity-curie-001\"\n",
    "    )\n",
    "    embeddings.append(response['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1267, 4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings_t = torch.tensor(embeddings)\n",
    "embeddings_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embeddings = []\n",
    "for q in questions:\n",
    "    response = openai.Embedding.create(\n",
    "        input=q,\n",
    "        model=\"text-similarity-curie-001\"\n",
    "    )\n",
    "    question_embeddings.append(response['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4875, 4096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings_q_t = torch.tensor(question_embeddings)\n",
    "embeddings_q_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_q_t, 'question_curie_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_t, 'learning_goal_curie_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('question_list.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(list(questions), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.47552"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(q.split()) for q in questions]) * 0.0200 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26248"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(lg.split()) for lg in learning_goals]) * 0.0200 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('question').agg(list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>Calculate the field of a collection of source charges of either sign</th>\n",
       "      <th>Analyze circuits that have an inductor and resistor in series</th>\n",
       "      <th>Analyze complex circuits using Kirchhoffs rules</th>\n",
       "      <th>Analyze elasticity and plasticity on a stress-strain diagram</th>\n",
       "      <th>Analyze one-dimensional and two-dimensional relative motion problems using the position and velocity vector equations.</th>\n",
       "      <th>Analyze the reason for the sparkle of diamonds</th>\n",
       "      <th>Answer qualitative questions about the effects of thermal expansion</th>\n",
       "      <th>Apply Gausss law in appropriate systems</th>\n",
       "      <th>Apply Gausss law to determine the electric field of a system with one of these symmetries</th>\n",
       "      <th>...</th>\n",
       "      <th>Writing Formulas for Ionic Compounds</th>\n",
       "      <th>Writing Hybridization and Bonding Schemes Using Valence Bond Theory</th>\n",
       "      <th>Writing Lewis Structures for Compounds Having Expanded Octets</th>\n",
       "      <th>Writing Lewis Structures for Covalent Compounds</th>\n",
       "      <th>Writing Lewis Structures for Polyatomic Ions</th>\n",
       "      <th>Writing Molecular and Empirical Formulas</th>\n",
       "      <th>Writing Nuclear Equations for Alpha Decay</th>\n",
       "      <th>Writing Nuclear Equations for Beta Decay, Positron Emission, and Electron Capture</th>\n",
       "      <th>Writing Orbital Diagrams</th>\n",
       "      <th>Writing Resonance Lewis Structures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a) A 200-turn circular loop of radius 50.0 cm...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a) A 22.0-kg child is riding a playground mer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(a) A 5.0-kg rock at a temperature of 20C is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a) A 5.00-kg squid initially at rest ejects 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(a) A cosmic ray proton moving toward Earth at...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  (a) A 200-turn circular loop of radius 50.0 cm...   \n",
       "1  (a) A 22.0-kg child is riding a playground mer...   \n",
       "2  (a) A 5.0-kg rock at a temperature of 20C is ...   \n",
       "3  (a) A 5.00-kg squid initially at rest ejects 0...   \n",
       "4  (a) A cosmic ray proton moving toward Earth at...   \n",
       "\n",
       "    Calculate the field of a collection of source charges of either sign  \\\n",
       "0                                                  0                       \n",
       "1                                                  0                       \n",
       "2                                                  0                       \n",
       "3                                                  0                       \n",
       "4                                                  0                       \n",
       "\n",
       "   Analyze circuits that have an inductor and resistor in series  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   Analyze complex circuits using Kirchhoffs rules  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   Analyze elasticity and plasticity on a stress-strain diagram  \\\n",
       "0                                                  0              \n",
       "1                                                  0              \n",
       "2                                                  0              \n",
       "3                                                  0              \n",
       "4                                                  0              \n",
       "\n",
       "   Analyze one-dimensional and two-dimensional relative motion problems using the position and velocity vector equations.  \\\n",
       "0                                                  0                                                                        \n",
       "1                                                  0                                                                        \n",
       "2                                                  0                                                                        \n",
       "3                                                  0                                                                        \n",
       "4                                                  0                                                                        \n",
       "\n",
       "   Analyze the reason for the sparkle of diamonds  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   Answer qualitative questions about the effects of thermal expansion  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                                  0                     \n",
       "4                                                  0                     \n",
       "\n",
       "   Apply Gausss law in appropriate systems  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   Apply Gausss law to determine the electric field of a system with one of these symmetries  \\\n",
       "0                                                  0                                            \n",
       "1                                                  0                                            \n",
       "2                                                  0                                            \n",
       "3                                                  0                                            \n",
       "4                                                  0                                            \n",
       "\n",
       "   ...  Writing Formulas for Ionic Compounds  \\\n",
       "0  ...                                     0   \n",
       "1  ...                                     0   \n",
       "2  ...                                     0   \n",
       "3  ...                                     0   \n",
       "4  ...                                     0   \n",
       "\n",
       "   Writing Hybridization and Bonding Schemes Using Valence Bond Theory  \\\n",
       "0                                                  0                     \n",
       "1                                                  0                     \n",
       "2                                                  0                     \n",
       "3                                                  0                     \n",
       "4                                                  0                     \n",
       "\n",
       "   Writing Lewis Structures for Compounds Having Expanded Octets  \\\n",
       "0                                                  0               \n",
       "1                                                  0               \n",
       "2                                                  0               \n",
       "3                                                  0               \n",
       "4                                                  0               \n",
       "\n",
       "   Writing Lewis Structures for Covalent Compounds  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "   Writing Lewis Structures for Polyatomic Ions  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   Writing Molecular and Empirical Formulas  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   Writing Nuclear Equations for Alpha Decay  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   Writing Nuclear Equations for Beta Decay, Positron Emission, and Electron Capture  \\\n",
       "0                                                  0                                   \n",
       "1                                                  0                                   \n",
       "2                                                  0                                   \n",
       "3                                                  0                                   \n",
       "4                                                  0                                   \n",
       "\n",
       "   Writing Orbital Diagrams  Writing Resonance Lewis Structures  \n",
       "0                         0                                   0  \n",
       "1                         0                                   0  \n",
       "2                         0                                   0  \n",
       "3                         0                                   0  \n",
       "4                         0                                   0  \n",
       "\n",
       "[5 rows x 1268 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(\n",
    "    data, columns=['learning_goal'], prefix='', prefix_sep=''\n",
    ").groupby('question').sum(numeric_only=True).reset_index()\n",
    "\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(a) A 200-turn circular loop of radius 50.0 cm...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(a) A 22.0-kg child is riding a playground mer...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(a) A 5.0-kg rock at a temperature of 20C is ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(a) A 5.00-kg squid initially at rest ejects 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(a) A cosmic ray proton moving toward Earth at...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  (a) A 200-turn circular loop of radius 50.0 cm...   \n",
       "1  (a) A 22.0-kg child is riding a playground mer...   \n",
       "2  (a) A 5.0-kg rock at a temperature of 20C is ...   \n",
       "3  (a) A 5.00-kg squid initially at rest ejects 0...   \n",
       "4  (a) A cosmic ray proton moving toward Earth at...   \n",
       "\n",
       "                                              labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dummies.copy()\n",
    "train_data['labels'] = train_data[train_data.columns[1:]].apply(\n",
    "    lambda l: list(l),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "train_data = train_data[train_data.columns[[0, -1]]]\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    ")\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "eval_data = train_data.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Optional model configuration\n",
    "model_args = MultiLabelClassificationArgs(num_train_epochs=5, output_dir='test_output')\n",
    "\n",
    "# Create a MultiLabelClassificationModel\n",
    "model = MultiLabelClassificationModel(\n",
    "    \"bert\",\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(train_data.iloc[0]['labels']),\n",
    "    args=model_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\.conda\\envs\\cs330\\lib\\site-packages\\simpletransformers\\classification\\classification_model.py:612: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91010497dd8c418eb0ebcd7847fe86a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_0_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efd6c062f304703bb90e00372d6f96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c72db25dd6c4cc987e653cb166d5cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 5:   0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a07f731b8b45dab6bcaf2816ec0186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 5:   0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54df3ea94964349a2b1d45350c96cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 5:   0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3a4d0527ee4fbc87ccdef8606a2e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 5:   0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abaae962240a4a1c9659b917ffb1f85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 4 of 5:   0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to test_output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3050, 0.04384645906353339)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba4496f57fa42e2aa15ed14cff1b5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875c2e414d11485d94d8a1e88b59d9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(list(eval_data['question'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, raw_outputs = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1267)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.96 * np.std(np.array(preds).flatten()) / np.sqrt(len(np.array(preds).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1267)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.stack([np.array(v) for v in eval_data['labels'].values])\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\.conda\\envs\\cs330\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "accuracy_score(y_true=labels.flatten(), y_pred=np.array(preds).flatten())\n",
    "precision_score(y_true=labels.flatten(), y_pred=np.array(preds).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\.conda\\envs\\cs330\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 384)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "from openstax_dataset import nWaykShotDataset\n",
    "\n",
    "dataset = nWaykShotDataset(\n",
    "    num_support=5,\n",
    "    num_query=2,\n",
    "    tokenizer=None,\n",
    "    task_embedding_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amirz\\Source\\smartstem\\smartstem-ai\\openstax_dataset.py:205: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  'task_embeds': torch.tensor([self.learning_goal_embeddings[index]]).repeat(2 * self.num_support, 1).unsqueeze(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support, _, query, _ = dataset[0]\n",
    "support['task_embeds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('prajjwal1/bert-mini')\n",
    "\n",
    "tokens = tokenizer(\n",
    "    sentences,\n",
    "    return_tensors='pt',\n",
    "    max_length=256,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokens.update({'task_emeds': torch.zeros((3, 256))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'task_emeds'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "lg_embeddings = torch.load('learning_goal_curie_embeddings.pt')\n",
    "q_embeddings = torch.load('question_curie_embeddings.pt')\n",
    "\n",
    "with open('learning_goal_list.txt', encoding='utf-8') as f:\n",
    "    lg_list = [line.strip() for line in f]\n",
    "\n",
    "with open('question_list.json', encoding='utf-8') as f:\n",
    "    q_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875, torch.Size([4875, 4096]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list), q_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, torch.Size([1267, 4096]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lg_embeddings), lg_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1267])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = -torch.nn.functional.cosine_similarity(q_embeddings[:1], lg_embeddings, dim=-1)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1267])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = torch.cdist(q_embeddings[:1], lg_embeddings)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = dists.squeeze().tolist()\n",
    "len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_lg = list(zip(distances, lg_list))\n",
    "\n",
    "ranked_dists = sorted(dist_to_lg, key=lambda t: t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explain how you could experimentally determine whether the outside temperature is higher or lower than 0 C (32 F) without using a thermometer.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the relation between the intermolecular forces present within a substance and the temperatures associated with changes in its physical state\n",
      "Determine the dependence of the magnetic field from a thin, straight wire based on the distance from it and the current flowing in the wire.\n",
      "Determine the magnetic flux through a surface, knowing the strength of the magnetic field, the surface area, and the angle between the normal to the surface and the magnetic field\n",
      "Describe the processes represented by typical heating and cooling curves, and compute heat flows and enthalpy changes accompanying these processes\n",
      "Describe the effect of solute concentration on various solution properties (vapor pressure, boiling point, freezing point, and osmotic pressure)\n",
      "Determine the angular frequency, frequency, and period of a simple pendulum in terms of the length of the pendulum and the acceleration due to gravity\n",
      "Determining the Effect of a Temperature Change on Equilibrium\n",
      "Explain the differences between centripetal acceleration and tangential acceleration resulting from nonuniform circular motion.\n",
      "Determine the equilibrium separation distance between atoms in a diatomic molecule from the vibrational-rotational absorption spectrum\n",
      "Explain how the Biot-Savart law is used to determine the magnetic field due to a current in a loop of wire at a point along a line perpendicular to the plane of the loop.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(ranked_dists[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "OPENSTAX_COURSES = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1', \n",
    "    'University Physics Volume 2', \n",
    "    'University Physics Volume 3'\n",
    "]\n",
    "\n",
    "PRINCIPLES_OF_CHEMISTRY_COURSE = 'Principles of Chemistry 3rd edition'\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in OPENSTAX_COURSES\n",
    "] + [util.load_principles_of_chemistry_course(PRINCIPLES_OF_CHEMISTRY_COURSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>learning_goal</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Outline the historical development of chemistry</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Provide examples of the importance of chemistr...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Describe the scientific method</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Differentiate among hypotheses, theories, and ...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain how you could experimentally determine...</td>\n",
       "      <td>Provide examples illustrating macroscopic, mic...</td>\n",
       "      <td>Chemistry 2e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Explain how you could experimentally determine...   \n",
       "1  Explain how you could experimentally determine...   \n",
       "2  Explain how you could experimentally determine...   \n",
       "3  Explain how you could experimentally determine...   \n",
       "4  Explain how you could experimentally determine...   \n",
       "\n",
       "                                       learning_goal        course  \n",
       "0    Outline the historical development of chemistry  Chemistry 2e  \n",
       "1  Provide examples of the importance of chemistr...  Chemistry 2e  \n",
       "2                     Describe the scientific method  Chemistry 2e  \n",
       "3  Differentiate among hypotheses, theories, and ...  Chemistry 2e  \n",
       "4  Provide examples illustrating macroscopic, mic...  Chemistry 2e  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['question'] == q_list[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from models.protobert import BertModel\n",
    "from trainer import ProtoNet\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "network = BertModel.from_pretrained('bert-base-uncased', is_tam=True)\n",
    "\n",
    "protonet = ProtoNet(\n",
    "    network, \n",
    "    0.00001, \n",
    "    'bert_full_s5_q2_b2_tam',\n",
    "    num_epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint iteration 6.\n"
     ]
    }
   ],
   "source": [
    "protonet.load(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstax_dataset import CourseTestDataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "task_embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "dataset = CourseTestDataset('Chem 31A', 5, 2, tokenizer, max_length=256, task_embedding_model=task_embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_by_lg = dataset.data_by_learning_goal\n",
    "lgs = list(data_by_lg.index)\n",
    "len(lgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict(task_batch, protonet):\n",
    "    with torch.no_grad():\n",
    "        predictions_batch = []\n",
    "        for task in task_batch:\n",
    "            support, labels_support, query, labels_query = task\n",
    "\n",
    "            support = {k: v.to(protonet._device) for k, v in support.items()}\n",
    "            query = {k: v.to(protonet._device) for k, v in query.items()}\n",
    "            labels_support = labels_support.to(protonet._device)\n",
    "            labels_query = labels_query.to(protonet._device)\n",
    "            n = 2\n",
    "            k = labels_support.shape[0] // n\n",
    "            # (nk, dim)\n",
    "            support_representations = protonet._network(\n",
    "                **support\n",
    "            )[1]\n",
    "\n",
    "            # (nq, dim)\n",
    "            query_representations = protonet._network(\n",
    "                **query\n",
    "            )[1]\n",
    "\n",
    "            # (n, dim)\n",
    "            prototypes = support_representations.view(n, k, -1).mean(dim=1)\n",
    "\n",
    "            # (nq, n) \n",
    "            query_distances = torch.cdist(query_representations, prototypes) \n",
    "            query_logits = F.softmax(-query_distances, dim=1)\n",
    "\n",
    "            # predictions_batch.append(torch.argmax(query_logits, dim=-1))\n",
    "            predictions_batch.append(query_logits)\n",
    "    return torch.stack(predictions_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 98/98 [08:12<00:00,  5.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 54, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "for task_batch in tqdm(dataset):\n",
    "    predictions.append(predict(task_batch, protonet).squeeze())\n",
    "    \n",
    "predictions = torch.stack(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 98/98 [00:27<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "all_labels = [[l[-1].item() for l in task_batch] for task_batch in tqdm(dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "\n",
    "def get_recall(predictions, k):\n",
    "    recalls = []\n",
    "    for labels, pred in zip(all_labels, predictions):\n",
    "        preds_and_lgs = list(zip(lgs, pred.cpu()[:, 1].tolist()))\n",
    "        ranked = sorted(preds_and_lgs, key=lambda t: t[1], reverse=True)\n",
    "        top_k = [t[0] for t in ranked[:k]]\n",
    "\n",
    "        top_k_preds = [lg in top_k for lg in lgs]\n",
    "        recalls.append(recall_score(y_true=labels, y_pred=top_k_preds))\n",
    "    return np.mean(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = list(range(1, 21))\n",
    "\n",
    "recall_over_k = []\n",
    "for k in ks:\n",
    "    recall_over_k.append(get_recall(predictions, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame({'k': ks, 'recall': recall_over_k})\n",
    "\n",
    "sns.set_palette('pastel')\n",
    "lineplot = sns.lineplot(data=data, x='k', y='recall').set(title='Recall Over Top-K Outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_2_tam_T = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_and_lgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = sorted(preds_and_lgs, key=lambda t: t[1], reverse=True)\n",
    "\n",
    "k = 5\n",
    "top_k = [t[0] for t in ranked[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Predict how any two independent variables of a gas (P, V, n, R, T) change if the others are held constant.',\n",
       " 'Calculate how vapor pressure will change as the pressure, volume, temperature, or amount are varied',\n",
       " 'Identify when a limiting reagent calculation is necessary.',\n",
       " 'Calculate the work done by or on a gas.',\n",
       " 'Know how boiling point relates to vapor pressure']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Calculate the work done by or on a gas.'], dtype='object', name='learning_goal')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_lgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lg in top_k for lg in true_lgs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Chem 31A Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_chem31a_learning_goals(filename='chem31a_learning_goal_list.txt'):\n",
    "    learning_goals = {}\n",
    "\n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        current_unit = None\n",
    "        current_letter = ord('a')\n",
    "        lines = [l.strip() for l in f.readlines()]\n",
    "        for line in lines[1:]:\n",
    "            unit = re.match('[0-9]\\.', line)\n",
    "            if unit:\n",
    "                number = int(unit.group(0)[:-1])\n",
    "                assert number not in learning_goals\n",
    "                learning_goals[number] = {}\n",
    "                learning_goals[number]['title'] = line[len(unit.group(0)):]\n",
    "                current_unit = number\n",
    "                current_letter = ord('a')\n",
    "            else:\n",
    "                assert current_unit is not None\n",
    "                assert current_unit in learning_goals\n",
    "                learning_goals[current_unit][chr(current_letter)] = line\n",
    "                current_letter += 1\n",
    "    return learning_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def parse_chem31a_questions(filename, year='2021'):\n",
    "    exam_path = os.path.join('Chem 31A Dataset', year, filename)\n",
    "    with open(exam_path, encoding='utf-8') as f:\n",
    "        questions = {}\n",
    "        lines = [l.strip() for l in f.readlines() if l.strip() != '']\n",
    "        current_q_num = None\n",
    "        current_q_title = None\n",
    "        current_sub_q_num = None\n",
    "        for line in lines:\n",
    "            q_num = re.match('[0-9]+\\) ', line)\n",
    "            if q_num:\n",
    "                q_num = q_num.group(0)\n",
    "                current_q_num = int(q_num[:q_num.find(')')])\n",
    "                current_q_title = line[len(q_num):]\n",
    "                assert q_num not in questions\n",
    "                questions[current_q_num] = {}\n",
    "            # first question is always multiple choice with roman numerals\n",
    "            elif current_q_num == 1:\n",
    "                sub_q_num = re.match('[iv]+\\) ', line)\n",
    "                if sub_q_num:\n",
    "                    sub_q_num = sub_q_num.group(0)\n",
    "                    current_sub_q_num = sub_q_num[:-2]\n",
    "                    assert current_q_num in questions\n",
    "                    assert current_sub_q_num not in questions[current_q_num]\n",
    "                    questions[current_q_num][current_sub_q_num] = line[len(sub_q_num):]\n",
    "                else:\n",
    "                    assert current_q_num in questions\n",
    "                    if current_sub_q_num in questions[current_q_num]:\n",
    "                        questions[current_q_num][current_sub_q_num] += line\n",
    "                    else:\n",
    "                        current_q_title += line\n",
    "            # second question is always short answer with letters\n",
    "            elif current_q_num == 2:\n",
    "                # skip roman numerals i and v\n",
    "                sub_q_num = re.match('[a-h|j-u|w-z]\\) ', line)\n",
    "                if sub_q_num:\n",
    "                    sub_q_num = sub_q_num.group(0)\n",
    "                    current_sub_q_num = sub_q_num[:-2]\n",
    "                    assert current_q_num in questions\n",
    "                    assert current_sub_q_num not in questions[current_q_num]\n",
    "                    questions[current_q_num][current_sub_q_num] = line[len(sub_q_num):]\n",
    "                else:\n",
    "                    assert current_q_num in questions\n",
    "                    if current_sub_q_num in questions[current_q_num]:\n",
    "                        questions[current_q_num][current_sub_q_num] += line\n",
    "                    else:\n",
    "                        current_q_title += line\n",
    "            # all other questions use the question title, always letters\n",
    "            else:\n",
    "                # skip roman numerals i and v\n",
    "                sub_q_num = re.match('[a-h|j-u|w-z]\\) ', line)\n",
    "                if sub_q_num:\n",
    "                    sub_q_num = sub_q_num.group(0)\n",
    "                    current_sub_q_num = sub_q_num[:-2]\n",
    "                    assert current_q_num in questions\n",
    "                    assert current_sub_q_num not in questions[current_q_num]\n",
    "                    # make sure to include the question title for these!\n",
    "                    questions[current_q_num][current_sub_q_num] = current_q_title + line[len(sub_q_num):]\n",
    "                else:\n",
    "                    assert current_q_num in questions\n",
    "                    if current_sub_q_num in questions[current_q_num]:\n",
    "                        questions[current_q_num][current_sub_q_num] += line\n",
    "                    else:\n",
    "                        current_q_title += line\n",
    "    return questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_chem31a_questions_to_learning_goals(filename, year='2021'):\n",
    "    file_path = os.path.join('Chem 31A Dataset', year, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    questions_to_lgs = {}\n",
    "    for i, row in df.iterrows():\n",
    "        question = row['Exam Q#']\n",
    "        # ignore empty question cells (only applicable for Exam 3)\n",
    "        if pd.isna(question):\n",
    "            continue\n",
    "        q_num = re.match('[0-9]+', question).group(0)\n",
    "        sub_q_num = question[len(q_num):]\n",
    "        # prevent cases like bi, bii\n",
    "        if not sub_q_num.startswith('i') and not sub_q_num.startswith('v'):\n",
    "            sub_q_num = sub_q_num[0]\n",
    "        q_num = int(q_num)\n",
    "        if q_num not in questions_to_lgs:\n",
    "            questions_to_lgs[q_num] = {}\n",
    "        if sub_q_num in questions_to_lgs[q_num]:\n",
    "            continue\n",
    "        questions_to_lgs[q_num][sub_q_num] = []\n",
    "        for lg_num, col in enumerate(df.columns[2:10], start=1):\n",
    "            # ignore empty cells\n",
    "            if pd.isna(row[col]):\n",
    "                continue\n",
    "            lgs = [c.lower() for c in row[col] if c.isalpha()]\n",
    "            questions_to_lgs[q_num][sub_q_num].extend(\n",
    "                [(lg_num, lg) for lg in lgs]\n",
    "            )\n",
    "    return questions_to_lgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chem31a_course(year='2021'):\n",
    "    learning_goals = load_chem31a_learning_goals()\n",
    "\n",
    "    data = []\n",
    "    for e in range(1, 5):\n",
    "        questions = parse_chem31a_questions(f'Chem31A_2021_Exam{e}.txt', year=year)\n",
    "        questions_to_learning_goals = load_chem31a_questions_to_learning_goals(\n",
    "            f'questions_to_learning_goals_exam{e}.csv', year=year\n",
    "        )\n",
    "        for q_num in questions:\n",
    "            for sub_q_num in questions[q_num]:\n",
    "                for lg in questions_to_learning_goals[q_num][sub_q_num]:\n",
    "                    data.append([\n",
    "                        questions[q_num][sub_q_num],\n",
    "                        learning_goals[lg[0]][lg[1]]\n",
    "                    ])\n",
    "    df = pd.DataFrame(data, columns=['question', 'learning_goal'])\n",
    "    df['course'] = 'Chem31A'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 3)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_chem31a_course()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['question'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'i': [(1, 'b'), (1, 'i')],\n",
       "  'ii': [(2, 'a'), (2, 'c')],\n",
       "  'iii': [(1, 'b'), (1, 'c')],\n",
       "  'iv': [(4, 'd')],\n",
       "  'v': [(4, 'd')]},\n",
       " 2: {'a': [(1, 'b')],\n",
       "  'bi': [(1, 'a'), (1, 'b'), (1, 'd'), (1, 'e'), (1, 'g')],\n",
       "  'bii': [(1, 'a')],\n",
       "  'c': [(1, 'b'), (1, 'c'), (1, 'd'), (1, 'e'), (1, 'g'), (1, 'i'), (4, 'b')]},\n",
       " 3: {'a': [(1, 'a'), (1, 'f')],\n",
       "  'b': [(1, 'a'), (1, 'f')],\n",
       "  'c': [(1, 'b'), (1, 'f')],\n",
       "  'd': [(1, 'b'), (1, 'f')]},\n",
       " 4: {'a': [(1, 'b'), (1, 'c'), (1, 'd'), (1, 'e'), (2, 'a'), (2, 'h')],\n",
       "  'b': [(1, 'b'), (2, 'a'), (2, 'c'), (2, 'h')]},\n",
       " 5: {'a': [(1, 'c')],\n",
       "  'b': [(1, 'h')],\n",
       "  'c': [(1, 'a'), (1, 'g')],\n",
       "  'd': [(1, 'b'), (1, 'g'), (1, 'i')]}}"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_to_learning_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'title': 'Dimensional Analysis and Stoichiometry',\n",
       "  'a': 'Apply chemical concepts in the laboratory, and use observations gained during experimentation to explain chemical phenomena',\n",
       "  'b': 'Apply dimensional analysis to guide problem solving',\n",
       "  'c': 'Know how to name ionic and covalent compounds for main group and transition metal elements.',\n",
       "  'd': 'Determine the number of moles or mass of product produced in a reaction that goes to completion.',\n",
       "  'e': 'Identify when a limiting reagent calculation is necessary.',\n",
       "  'f': 'Use experimental data to determine empirical and/or molecular formula',\n",
       "  'g': 'Apply stoichiometry to quantitatively and qualitatively make predictions and draw conclusions about chemical reactions',\n",
       "  'h': 'Write and balance chemical and net-ionic equations',\n",
       "  'i': 'Apply the concept of percent by mass and percent by volume when solving problems.',\n",
       "  'j': 'Apply dilution formula (M1 V1    =  M2 V2 ) to calculate dilution volume or concentrations.'},\n",
       " 2: {'title': 'Gas Laws and Kinetic Molecular Theory',\n",
       "  'a': 'Use the ideal gas law (PV=nRT) to solve problems.',\n",
       "  'b': 'Sketch a graph of any two independent variables (P, V, n, R, T) of a gas',\n",
       "  'c': 'Predict how any two independent variables of a gas (P, V, n, R, T) change if the others are held constant.',\n",
       "  'd': 'Use pressure to calculate force exerted by a gas',\n",
       "  'e': 'Calculate the pressure exerted by a liquid in a barometer',\n",
       "  'f': 'Explain why the ideal gas law best approximates the behavior of noble and diatomic gasses, and how intermolecular forces give rise to non-ideal behavior in gasses',\n",
       "  'g': 'Calculate the number density and mass density of a gas',\n",
       "  'h': 'Use gas laws with stoichiometry to analyze chemical reactions of gasses',\n",
       "  'i': 'Use partial pressures, mole fractions, and total pressure of a mixture of gasses to create systems of equations',\n",
       "  'j': 'Calculate vapor pressure',\n",
       "  'k': 'Know how boiling point relates to vapor pressure',\n",
       "  'l': 'Calculate how vapor pressure will change as the pressure, volume, temperature, or amount are varied',\n",
       "  'm': 'Use the Clapeyron-Clausius equation to determine values for enthalpy of reaction, pressure, temperature, etc.',\n",
       "  'n': 'Sketch the distributions of velocity, speed, and kinetic energy as predicted by the Maxwell Boltzmann distribution',\n",
       "  'o': 'Relate average kinetic energy to temperature, calculate root mean squared (RMS) velocity',\n",
       "  'p': 'Use Grahams Law to calculate rates of effusion and make qualitative comparisons of effusion rates between different molecules'},\n",
       " 3: {'title': 'Chemical Reactions and Thermodynamics',\n",
       "  'a': 'Write and balance combustion equations for hydrocarbons, solve problems involving combustion',\n",
       "  'b': 'Identify endothermic and exothermic reactions.',\n",
       "  'c': 'Use the First Law of Thermodynamics to determine whether a system is open or closed.',\n",
       "  'd': 'Know the difference between systems and surroundings',\n",
       "  'e': 'Identify the difference between state functions (e.g. enthalpy) and path functions (e.g. work)',\n",
       "  'f': 'Calculate the work done by or on a gas.',\n",
       "  'g': 'Calculate the change in enthalpy associated with a phase change.',\n",
       "  'h': 'Calculate changes in energy, enthalpy, and temperature that result from a chemical reaction.',\n",
       "  'i': 'Analyze calorimetry experiments at constant pressure and constant volume.',\n",
       "  'j': 'Use Hess Law to calculate heats of reaction based on enthalpies of formation.'},\n",
       " 4: {'title': 'Structure of the Atom',\n",
       "  'a': 'Describe the structure of the atomic nucleus',\n",
       "  'b': 'Use atomic radius or other measurable dimensions of the atom to determine volume or other calculable properties.',\n",
       "  'c': 'Explain the difference between average atomic mass (formula weight) and the mass of a single isotope.',\n",
       "  'd': 'Determine the number of protons, neutrons, and electrons in an atom, isotope, compound, or molecule.',\n",
       "  'e': 'Determine the formula weight of a compound given the abundances of its isotopes.'},\n",
       " 5: {'title': 'Electrons and Quantum Properties',\n",
       "  'a': 'Evaluate the shell model of atomic electronic structure',\n",
       "  'b': 'Determine which AO corresponds to a given set of quantum numbers.',\n",
       "  'c': 'Understand and write electron configurations for atoms (s, p, and d blocks only)',\n",
       "  'd': 'Determine the energy needed or released when transitioning to different energy levels.',\n",
       "  'e': 'Use the relationship between the frequency and wavelength and velocity (speed) of a wave to calculate any one (freq, wavelength or velocity) given the other two.',\n",
       "  'f': 'Explain how (and why) different atoms emit different wavelengths of light.',\n",
       "  'g': 'Know how the photoelectric effect can be used to assess binding energy.',\n",
       "  'h': 'Apply knowledge about properties of light for UV-Visible spectroscopy or for measuring absorbance with Beer-Lambert law.',\n",
       "  'i': 'Understand and apply the wave- and particle-like properties of light.'},\n",
       " 6: {'title': 'Periodic Trends',\n",
       "  'a': 'Describe the electronic structure of atoms and molecules',\n",
       "  'b': 'Explain how electronic structure gives rise to periodic trends (i.e.,recognizing isoelectronic species)',\n",
       "  'c': 'Explain and predict periodic trends or atomic identity based on ionization energy, lattice energy, electronegativity, size, and effective nuclear charge',\n",
       "  'd': 'Given a set of data, explain any exceptions to an expected periodic trend based on electronic structure of the atom'},\n",
       " 7: {'title': 'Bonding, Lewis Structures, and Molecular Shapes',\n",
       "  'a': 'Define covalent and ionic bonding.',\n",
       "  'b': 'Determine if a bond is polar or non-polar',\n",
       "  'c': 'Use Lewis structures to describe covalent bonding',\n",
       "  'd': 'Determine whether a compound or molecule has multiple resonance structures',\n",
       "  'e': 'Determine the hybridization of an atom from a Lewis structure',\n",
       "  'f': 'Determine the 3D shapes of molecules and/or electronic geometry of an atom from a Lewis structure and VSEPR',\n",
       "  'g': 'Determine whether a molecule is polar (contains a permanent dipole moment)',\n",
       "  'h': 'Use experimental data (bond lengths, strength, angles) and/or resonance structures to explain or predict the 3-D structure of a molecule.',\n",
       "  'i': 'Identify sigma and pi bonds and describe the differences between their properties.',\n",
       "  'j': 'Draw and label orbitals, sigma bonds, and pi bonds on a molecule',\n",
       "  'k': 'Fill in a molecular orbital (MO) diagrams for diatomic molecules and calculate the bond order',\n",
       "  'l': 'Use a filled MO diagram to predict whether a molecule will be paramagnetic or diamagnetic.',\n",
       "  'm': 'Compare and contrast the valence bond model and molecular orbital model.'},\n",
       " 8: {'title': 'Intermolecular Forces and Macroscopic Properties',\n",
       "  'a': 'Know how intermolecular forces give rise to physical behavior',\n",
       "  'b': 'Know the four types of intermolecular forces and their relative strengths.',\n",
       "  'c': 'Predict which intermolecular forces are most consequential for the physical properties of a given compound.',\n",
       "  'd': 'Rank the boiling point, melting point, or vapor pressure of similar compounds based on the strengths of their intermolecular forces.',\n",
       "  'e': 'Know how hydrogen bonding gives rise to the unusual properties of water.',\n",
       "  'f': 'Define hydrophobic and hydrophilic and predict when a compound would be hydrophobic or hydrophilic.',\n",
       "  'g': 'Interpret a phase diagram to determine what phase change may occur for a given change in pressure or temperature',\n",
       "  'h': 'Determine a melting or boiling point at a given pressure using a phase diagram'}}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'i': \"Clair Patterson determined in 1969 that surface waters contain 8791 milligrams (mg) of Pb forevery 25.1 g of seawater, which he attributed to the widespread use of leaded gasoline at thetime. What was the lead concentration in ppm (by mass) in this sample?(a) 3.50 x 102 ppm(b) 0.350 ppm(c) 3.5 x 105 ppm(d) 35.0 ppmii) You fill a balloon up with He in Palo Alto, where the pressure is 0.96 atm, and then drive withyour balloon to your cousin's birthday party in Denver, where the pressure is 0.81 atm. If thevolume of the balloon in Palo Alto is 2.7 L, what will be the volume of the balloon in Denver?Assume that no He escapes from the balloon during the road trip and that the temperature inPalo Alto and Denver are the same.(a) 1.2 L(b) 2.7 L(c) 3.2 L(d) 2.3 L(e) Not enough information to say.iii) Household bleach is typically sold at a concentration of 1.11 M NaOCl (aqueous), but fordisinfection it is recommended to use a solution of 23.1 mM sodium hypochlorite (aqueous).What is the maximum volume of disinfecting solution you can prepare from a 3.79 L bottleof household bleach purchased from the store?(a) 182 L(b) 15.6 L(c) 37.9 L(d) 111 L(e) Not enough information to sayiv) Different ions of the same element differ in the number of:(a) electrons.(b) neutrons.(c) protons.(d) neutrons and protons.(e) electrons and protons.\",\n",
       "  'v': 'How many electrons does the Ba2+ ion possess?(a) 56(b) 58(c) 54(d) 55(e) 88'},\n",
       " 2: {'a': 'Suppose Elon Musk drives from Los Angeles to San Francisco(382 miles) in a 2021 Tesla Model 3, which has standard-rangebattery with a rating of 24.0 kWh/100 miles. If he charges his caron the California grid, where 48.35% of electricity is generatedfrom natural gas, 0.170% from coal, 0.0200% from oil, and therest from renewable energy (assume no CO2 is emitted fromrenewable energy), how many kilograms of CO2 were emitted togenerate the electricity required for his trip? (See Table below)',\n",
       "  'b': 'We saw in lab that the reaction of acetic acid with sodiumbicarbonate produces water, carbon dioxide, and sodium acetate(see balanced equation below). You add 95 mL of a 0.933 molar(M) aqueous solution of acetic acid (molar mass: 60.05 g/mol)containing red cabbage pH indicator to an open beaker andrecord the total mass as 275 g. You then add 5.0 g of sodiumbicarbonate (molar mass: 84.0 g/mol) to the jar, stir, and wait forthe reaction to finish. After the reaction is complete, you weigh the jar again. Assume the mass of pH indicator is negligible (it doesnt contribute anything to the overall mass).i.) What color is the liquid in the beaker after the reaction is complete? Justify your answer with acalculation.ii.) When you weigh the jar after the reaction, do you expect the mass to be about equal to 280g, less than 280g or more than 280g? Briefly explain your answer.',\n",
       "  'c': 'Aqueous lead nitrate reacts with potassium iodide to form solid lead iodide as a precipitate. Thebalanced molecular equation is shown below. If 1.54 g of potassium iodide reacts completely withexcess lead nitrate in an aqueous solution to form 1.46 g of lead iodide precipitate, what is the percentyield of the reaction?Molar Mass (Pb(NO3)2): 331.2 g/mol; (KI): 166.0 g/mol; (PbI2): 461.0 g/mol; (KNO3): 101.1 g/molPb(NO3)2 (aq) + 2KI (aq)  PbI2 (s) + 2KNO3 (aq)'},\n",
       " 3: {'a': '[35 points] You obtain a small sample of an unknown compound extracted from the bark of a SouthAmerican tree. The indigenous people used powders of this bark to treat shivering. To identify thiscompound, the following experiments were carried out.Exp. #1: 25.10 mg of a sample of the pure compound was combusted to yield 18.58 mg carbonExp. #2: 25.10 mg of a sample of the pure compound was analyzed to yield 2.167 mg nitrogenExp. #3: 25.10 mg of a sample of the pure compound was combusted to yield 1.872 mghydrogenExp. #4: X-ray photoelectron spectroscopy (well learn this technique later) indicated the purecompound contained only the following elements: C, H, N, O.Exp. #5: A low resolution mass spectrum of the pure compound yield an ion corresponding tothe mass 324 amu.Assuming you dont know anything about this compound already, which experiment(s) areboth sufficient and necessary to allow you to determine the empirical formula of thiscompound (circle all that apply).1 2 3 4 5',\n",
       "  'b': '[35 points] You obtain a small sample of an unknown compound extracted from the bark of a SouthAmerican tree. The indigenous people used powders of this bark to treat shivering. To identify thiscompound, the following experiments were carried out.Exp. #1: 25.10 mg of a sample of the pure compound was combusted to yield 18.58 mg carbonExp. #2: 25.10 mg of a sample of the pure compound was analyzed to yield 2.167 mg nitrogenExp. #3: 25.10 mg of a sample of the pure compound was combusted to yield 1.872 mghydrogenExp. #4: X-ray photoelectron spectroscopy (well learn this technique later) indicated the purecompound contained only the following elements: C, H, N, O.Exp. #5: A low resolution mass spectrum of the pure compound yield an ion corresponding tothe mass 324 amu.Assuming you dont know anything about this compound already, which experiment(s) areboth sufficient and necessary to allow you to determine the molecular formula of thiscompound (circle all that apply).1 2 3 4 5',\n",
       "  'c': '[35 points] You obtain a small sample of an unknown compound extracted from the bark of a SouthAmerican tree. The indigenous people used powders of this bark to treat shivering. To identify thiscompound, the following experiments were carried out.Exp. #1: 25.10 mg of a sample of the pure compound was combusted to yield 18.58 mg carbonExp. #2: 25.10 mg of a sample of the pure compound was analyzed to yield 2.167 mg nitrogenExp. #3: 25.10 mg of a sample of the pure compound was combusted to yield 1.872 mghydrogenExp. #4: X-ray photoelectron spectroscopy (well learn this technique later) indicated the purecompound contained only the following elements: C, H, N, O.Exp. #5: A low resolution mass spectrum of the pure compound yield an ion corresponding tothe mass 324 amu.Determine the empirical formula of this compound'},\n",
       " 4: {'a': '[35 points]. 95.3 g of FeS2 and 54.0 L of O2 are sealed in a sealed 54.0 L container at 398 K and 1.20atm. These two react to generate Fe2O3 and sulfur dioxide. The molar mass of FeS2 is 119.99 g/moland that of Fe2O3(s) is 159.687 g/mol.4 FeS2(s) + 11 O2(g)  2 Fe2O3(s) + 8 SO2(g)How many grams of Fe2O3(s) would be generated?',\n",
       "  'b': '[35 points]. 95.3 g of FeS2 and 54.0 L of O2 are sealed in a sealed 54.0 L container at 398 K and 1.20atm. These two react to generate Fe2O3 and sulfur dioxide. The molar mass of FeS2 is 119.99 g/moland that of Fe2O3(s) is 159.687 g/mol.4 FeS2(s) + 11 O2(g)  2 Fe2O3(s) + 8 SO2(g)What would be the final pressure in the sealed 54.0L container if, at the end of the reaction, thecontainer was held at 25C?'},\n",
       " 5: {'a': '[35 points]. Hydrogen Fluoride is a highly toxic molecule used in many industrial chemicalprocesses. It can also be dissolved in water to form hydrofluoric acid. Exposure to hydrogen fluorideor hydrofluoric acid can not only cause tissue damage but can also cause systemic problems sincefluoride precipitates calcium out of solution, and a significant decrease in the concentration ofcalcium ions in the blood can cause cardiac arrest and death.Write the chemical formulas for hydrogen fluoride and calcium fluoride',\n",
       "  'b': '[35 points]. Hydrogen Fluoride is a highly toxic molecule used in many industrial chemicalprocesses. It can also be dissolved in water to form hydrofluoric acid. Exposure to hydrogen fluorideor hydrofluoric acid can not only cause tissue damage but can also cause systemic problems sincefluoride precipitates calcium out of solution, and a significant decrease in the concentration ofcalcium ions in the blood can cause cardiac arrest and death.Write the balanced net ionic equation for the precipitation of calcium fluoride from fluorideand calcium ions in your blood (an aqueous solution) - Dont forget to indicate states of matter!',\n",
       "  'c': '[35 points]. Hydrogen Fluoride is a highly toxic molecule used in many industrial chemicalprocesses. It can also be dissolved in water to form hydrofluoric acid. Exposure to hydrogen fluorideor hydrofluoric acid can not only cause tissue damage but can also cause systemic problems sincefluoride precipitates calcium out of solution, and a significant decrease in the concentration ofcalcium ions in the blood can cause cardiac arrest and death.A common treatment for skin exposure to hydrofluoric acid is to apply a gel containingcalcium gluconate to the site of exposure as soon as possible. Calcium gluconate is a calciumsalt that is soluble in water, where it dissolves into calcium and gluconate ions. In one or twosentences, describe how calcium gluconate likely works to treat hydrofluoric acid exposure.The molecular formula of calcium gluconate is Ca(C6H11O7)2.',\n",
       "  'd': '[35 points]. Hydrogen Fluoride is a highly toxic molecule used in many industrial chemicalprocesses. It can also be dissolved in water to form hydrofluoric acid. Exposure to hydrogen fluorideor hydrofluoric acid can not only cause tissue damage but can also cause systemic problems sincefluoride precipitates calcium out of solution, and a significant decrease in the concentration ofcalcium ions in the blood can cause cardiac arrest and death.Calcium gluconate gel is usually provided at a concentration of 2.5% calcium gluconate bymass. If you spill 5.00 mL of a 28.9 mM aqueous solution of hydrogen fluoride on your arm,what is the minimum mass of calcium gluconate gel you should apply to your arm toprecipitate all the fluoride? The molar mass of calcium gluconate is 430.37 g/mol.'}}"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'i': 'Which reaction would NOT describe a standard enthalpy of formation (Hf) for the product?(a) MgO(s) + CO2(g)  MgCO3(s)(b) Mg(s) + 12# O2(g)  MgO(s)(c) C(s) + O2(g)  CO2(g)(d) Mg(s) + C(s) + 32# O2(g)  MgCO3(s)ii) You have two sealed 1 liter water bottles on the table in front of you. At equilibrium, onecontains 500 mL of liquid water and one contains 5 mL of liquid water. Which 1 L bottlecontains a greater number of water molecules in the gas phase?(a) They contain the same number of water molecules in the gas phase.(b) The 1 liter bottle with 500mL of water will contain more water molecules in the gas phase(c) The 1 liter bottle with 5mL of water will contain more water molecules in the gas phase(d) It is not possible to tell without knowing the temperature of the room.iii) At a constant external pressure, if work was done by the system on the surroundings, would youexpect DE for the system to be greater than, less than or the same as the DH for the system?(a) E for the system would be greater than DH(b) E for the system would be less than DH(c) E for the system would the same as DH(d) It is impossible to determine without knowing the magnitude of work done.iv) Decreasing the external pressure on a liquid at constant temperature will do which of thefollowing:(a) Increase the boiling point, but not affect the vapor pressure(b) Decrease the boiling point, but not affect the vapor pressure(c) Increase the vapor pressure, therefore decreasing the boiling point(d) Increase the amount of heat required to boil a mole of the liquid(e) Both B and D are true',\n",
       "  'v': 'Consider the phase diagram at right. If the dashed line at 1atm of pressure is followed from 100 to 500C, whatphase changes will occur (in order of increasingtemperature)?(a) Condensation, followed by vaporization(b) Sublimation, followed by deposition(c) Vaporization, followed by deposition(d) Melting, followed by vaporization(e) No phase change will occur across the conditions specified.vi) Based on the phase diagram above, what conclusion can you make about the density of thesolid phase of this compound versus the density of its liquid phase?(a) The solid phase is more dense than the liquid phase(b) The solid phase is less dense than the liquid phase(c) The density of the liquid and solid phases is the same(d) It is impossible to make this comparison without knowing the molecular weight of thiscompoundvii)Which of the following ideal gases will occupy the greatest volume at 25C and 1 atm pressure?(a) 42 g CO(b) 42 g He(c) 42 g O2(d) 42 g Cl2(e) All of these gases would have the same volume at 25C and 1 atm pressure.viii) Choose the paramagnetic species from below.(a) Ti4+(b) Zr2+(c) Ar(d) All of the above are paramagnetic.(e) None of the above are paramagnetic.ix) For a hydrogen atom, which electronic transition would result in the emission of a photon withthe highest energy?(a) 3s  4p(b) 2p  6d(c) 5p  3s(d) 6p  5d'},\n",
       " 2: {'a': 'The heat of sublimation (!\"#) for a substance is generally found to be greater in magnitudethan the heat of vaporization ($%&) for the same substance. Briefly explain why in 2-3sentences.',\n",
       "  'b': 'At 25o C, a gas with a molecular weight of 44g/mol is contained in a vessel under very high-pressure conditions and has an initial density of 0.44 g/mL. The vessel is sealed by a movablepiston of radius 5.0 cm. Assuming the gas still behaves ideally, what is the magnitude of theforce (in Newtons) exerted by the gas on the piston?',\n",
       "  'c': 'For each molecule or mixture below, circle each of the intermolecular forces present.i) CH3OH    Dispersion  Dipole-Dipole  H-Bonding  Ion-dipoleii) (CH3)2SO    Dispersion  Dipole-Dipole  H-Bonding  Ion-dipoleiii) C2H6    Dispersion  Dipole-Dipole  H-Bonding  Ion-dipoleiv) B(OH)3   Dispersion  Dipole-Dipole  H-Bonding  Ion-dipolev) NaCl(aq)    Dispersion  Dipole-Dipole  H-Bonding  Ion-dipole',\n",
       "  'd': 'Dichloromethane (CH2Cl2) is a common laboratory solvent, but it must always be used in a fumehood to prevent inhalation of toxic vapors. The acceptable vapor pressure limit fordichloromethane is 12.67 Pa. At what temperature would it be safe to have an open containerof dichloromethane outside a fume hood? The Hvap of dichloromethane is 33.7 kJ/mole, andthe boiling point of dichloromethane is 39.6 C at 101325 Pa pressure. (Assume Hvap is nottemperature-dependent)',\n",
       "  'e': 'Match the molecular orbital with the correct picture for the electron probability distribution.(a) s2p(b) s2s(c) p2p(d) s*2p(e) s*2s(f) p*2p',\n",
       "  'f': 'The -lactam ring is a key component of penicillin antibiotics. Bacterial defense mechanisms usean enzyme and a water molecule to break the -lactam ring, which makes it ineffective as anantibiotic (example shown below)Using the provided bond energies:i) Estimate the enthalpy of reaction (Hrxn) for breaking the -lactam ring as shown above.ii) Is this an exothermic or endothermic reaction?'},\n",
       " 3: {'a': '[25 Points]. Diatomic carbon (C2) is a neutral molecule and an important precursor to the synthesis ofcomplex carbon structures like carbon nanotubes. You and a classmate have been asked to draw themost likely Lewis structure for C2.Your classmate suggests the following structure based on Lewis Structure guidelinesComplete the provided molecular orbital diagramfor C2. Explain why MO theory eithersupports or disputes the above Lewisstructure.',\n",
       "  'b': '[25 Points]. Diatomic carbon (C2) is a neutral molecule and an important precursor to the synthesis ofcomplex carbon structures like carbon nanotubes. You and a classmate have been asked to draw themost likely Lewis structure for C2.Draw best possible Lewis structure of C2 based on your answer to part (a). Include all non-bonding electrons and non-zero formal charges.',\n",
       "  'c': '[25 Points]. Diatomic carbon (C2) is a neutral molecule and an important precursor to the synthesis ofcomplex carbon structures like carbon nanotubes. You and a classmate have been asked to draw themost likely Lewis structure for C2.In general, quadruple bonds are not possible in main group elements like carbon. Explain why thisis the case using the concept of orbital overlap in sigma bonds and pi bonds. It may help todraw a picture (not required for full credit).'},\n",
       " 4: {'a': '[38 points]. Consider the diatomic neutral molecule nitric oxide (NO).Draw the two best resonance structures for NO. Include all non-zero formal charges and be sureto label your structures as major and minor contributors, if applicable.',\n",
       "  'b': '[38 points]. Consider the diatomic neutral molecule nitric oxide (NO).At high enough concentrations in the atmosphere, NO (g) will regularly dimerize; that is, two NOmolecules will combine to form dinitrogen dioxide N2O2(g). Draw the best Lewis dot structurefor N2O2 (g). What is the molecular geometry around a nitrogen atom in dinitrogen dioxide?',\n",
       "  'c': '[38 points]. Consider the diatomic neutral molecule nitric oxide (NO).Calculate the standard heat of dimerization of NO(g) to form dinitrogen dioxide N2O2(g).DHf (NO) = 91.121 kJ/molDHf (N2O2) = 171.12 kJ/mol',\n",
       "  'd': '[38 points]. Consider the diatomic neutral molecule nitric oxide (NO).Is the dimerization of NO(g) an enthalpically favorable process? Briefly explain why based onboth your calculations and Lewis dot structures above.'},\n",
       " 5: {'a': '[24 Points]. For the following questions, consider the first ionization energies of the atoms below.Rank the following in terms of increasing first ionization energy: (1 = lowest first ionizationenergy, 5 = highest first ionization energy____ ____ ____ ____ ____B     Li    F   N     O',\n",
       "  'b': '[24 Points]. For the following questions, consider the first ionization energies of the atoms below.Briefly explain why Nitrogen has a different first ionization energy than Boron in terms ofelectron and/or nuclear configuration (2-3 sentences).',\n",
       "  'c': '[24 Points]. For the following questions, consider the first ionization energies of the atoms below.The first ionization energy of Be is 0.90 MJ/ mol but the first ionization energy of B is 0.80MJ/mol. Considering the different wave-like properties of the electrons, explain why the firstionization energy of B is less than that of Be (2-3 sentences).'},\n",
       " 6: {'a': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.Draw the best Lewis structure for B(OH)3 clearly showing the correct 3D VSEPR moleculargeometry for Boron. Be sure to include all non-bonding electrons and non-zero formal charges.',\n",
       "  'b': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.Draw one additional resonance structure for B(OH)3 clearly showing the correct 3D VSEPRmolecular geometry for Boron. Be sure to include all non-bonding electrons and non-zero formalcharges.',\n",
       "  'c': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.Draw the best Lewis structure for B(OH)4 clearly showing the correct 3D VSEPR moleculargeometry for Boron. Be sure to include all non-bonding electrons and non-zero formal charges.',\n",
       "  'd': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.Based on Lewis bonding theory, predict whether the actual B-O bond lengths of B(OH)3 would bethe same, longer, or shorter than the actual B-O bond lengths of B(OH)4. The actual B-O bond lengths of B(OH)3 are predicted to be (circle one):the same as     shorter than      longer thanthe actual B-O bond lengths of B(OH)4.',\n",
       "  'e': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.Briefly explain your reasoning for your answer in part d).',\n",
       "  'f': '[42 Points]. Boron is a relatively rare element most commonly found in borosilicate glass. Twocompounds that Boron forms with hydroxide (OH) are B(OH)3 and B(OH)4.According to Valence Bond Theory:i) What is the hybridization of Boron in B(OH)3?ii) What is the hybridization of Boron in B(OH)4?'},\n",
       " 7: {'a': '[22 POINTS] The graph at the bottom of the page shows the distribution of molecular velocities fortwo different molecules (A and B) at the same temperature in a 2.0 L sealed container.Based on this data, answer the following by filling in the circle corresponding to the correct answer:Which molecule has the higher average kinetic energy (fill in the circle for one choice)?(a) Molecule A(b) Molecule B(c) Both are the same(d) You need more information',\n",
       "  'b': '[22 POINTS] The graph at the bottom of the page shows the distribution of molecular velocities fortwo different molecules (A and B) at the same temperature in a 2.0 L sealed container.Based on this data, answer the following by filling in the circle corresponding to the correct answer:Which molecule will have the higher rate of effusion (fill in the circle for one choice)?(a) Molecule A(b) Molecule B(c) Both are the same(d) You need more information',\n",
       "  'c': '[22 POINTS] The graph at the bottom of the page shows the distribution of molecular velocities fortwo different molecules (A and B) at the same temperature in a 2.0 L sealed container.Based on this data, answer the following by filling in the circle corresponding to the correct answer:Which molecule has the high molecular weight (fill in the circle for one choice)?(a) Molecule A(b) Molecule B(c) Both are the same(d) You need more information',\n",
       "  'd': '[22 POINTS] The graph at the bottom of the page shows the distribution of molecular velocities fortwo different molecules (A and B) at the same temperature in a 2.0 L sealed container.Based on this data, answer the following by filling in the circle corresponding to the correct answer:Which molecule would have the higher vapor pressure (fill in the circle for one choice)?(a) Molecule A(b) Molecule B(c) Both are the same(d) You need more information',\n",
       "  'e': '[22 POINTS] The graph at the bottom of the page shows the distribution of molecular velocities fortwo different molecules (A and B) at the same temperature in a 2.0 L sealed container.Based on this data, answer the following by filling in the circle corresponding to the correct answer:On the graph below, draw the distribution for molecule A if the system was cooled to a lowertemperature.'},\n",
       " 8: {'a': '[30 Points]. Lead acetate (MW = 325.3 g/mol) was used as a sweetener in Roman times but waslater discovered to be toxic. Lead acetate poisoning was thought to be the cause of the demise ofPope Clement II and Beethoven. It is formed by boiling lead in vinegar. Vinegar is generally an0.833 M solution of acetic acid in water (CH3CO2H(aq)).Pb0 (s) + 2 CH3CO2H(aq)  Pb(CH3CO2)2 (aq) + H2(g)If 225 mL of vinegar is boiled in pitcher containing 40.0 g of Pb and the reaction goes tocompletion, what concentration of lead acetate will be produced?',\n",
       "  'b': '[30 Points]. Lead acetate (MW = 325.3 g/mol) was used as a sweetener in Roman times but waslater discovered to be toxic. Lead acetate poisoning was thought to be the cause of the demise ofPope Clement II and Beethoven. It is formed by boiling lead in vinegar. Vinegar is generally an0.833 M solution of acetic acid in water (CH3CO2H(aq)).Pb0 (s) + 2 CH3CO2H(aq)  Pb(CH3CO2)2 (aq) + H2(g)Lead acetate is toxic at a concentration of 714 mg/kg (714 mg lead acetate/ 1.00 kg water). Basedon your answer to part a), would the concentration of lead acetate produced be toxic? Use acalculation to support your conclusion.'},\n",
       " 9: {'a': '[43 POINTS]. A 50.0mL Erlenmeyer flask completely full of water has aballoon attached to the top. The balloon is full of NO2 gas which willreact with the water according to the following equation:3NO2(g) + H2O(l)  2HNO3(aq) + NO(g)Use the following equations to determine the change in enthalpy for thisreaction:2NO(g) + O2(g)  2NO2(g) Hrxn = -116kJ/mol2N2(g) + 5O2(g) + 2H2O(l)  4HNO3(aq) Hrxn = -256kJ/molN2(g) + O2(g)  2NO(g) Hrxn = +183kJ/mol',\n",
       "  'b': '[43 POINTS]. A 50.0mL Erlenmeyer flask completely full of water has aballoon attached to the top. The balloon is full of NO2 gas which willreact with the water according to the following equation:3NO2(g) + H2O(l)  2HNO3(aq) + NO(g)Calculate the work done on/by the balloon during the reaction if the initial volume of the fullballoon is 1.00L, the pressure inside the balloon is 1.00 atm, and the initial temperature of theentire system is 298K. Assume that the temperature returns to 298K following the reaction andthere is a constant external pressure of 1.00atm. Be careful to indicate correct sign.'},\n",
       " 10: {'a': '[43 POINTS]. A glowing red hot 555g piece of heated iron, initially at 859C, is dropped into anopen bucket filled with 7.50*102mL of warm water, initially at 75.0C. The water begins to steam.The heat capacity of iron is 0.460J/(gC) and the heat capacity of water is 4.18 J/(gC). The heatof vaporization (Hvap) for water is 2257 J/g at 100.0 C.Explain why steam is rising from the bucket. Discuss this process in terms of heat exchange andthe chemical processes occurring. Will the amount of water in the bucket increase, decrease, orstay the same during this process?',\n",
       "  'b': '[43 POINTS]. A glowing red hot 555g piece of heated iron, initially at 859C, is dropped into anopen bucket filled with 7.50*102mL of warm water, initially at 75.0C. The water begins to steam.The heat capacity of iron is 0.460J/(gC) and the heat capacity of water is 4.18 J/(gC). The heatof vaporization (Hvap) for water is 2257 J/g at 100.0 C.Once the steaming has stopped and the system has reached equilibrium, how many milliliters ofwater remain in the bucket? Assume all heat is transferred only between the water and the iron.'}}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_chem31a_questions('Chem31A_2021_Exam4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "line = '1) Multiple Choice: [35 POINTS] For questions i-v, Please fill in the circle corresponding to the'\n",
    "match = re.match('[0-9]+\\) ', line)\n",
    "if match:\n",
    "    print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1) Multiple Choice: [35 POINTS] For questions i-v, Please fill in the circle corresponding to the',\n",
       " 'correct answer, as shown in the example below. Make no marks in any of the other circles',\n",
       " '',\n",
       " 'i) Clair Patterson determined in 1969 that surface waters contain 8791 milligrams (mg) of Pb for',\n",
       " 'every 25.1 g of seawater, which he attributed to the widespread use of leaded gasoline at the',\n",
       " 'time. What was the lead concentration in ppm (by mass) in this sample?',\n",
       " '(a) 3.50 x 102 ppm',\n",
       " '(b) 0.350 ppm',\n",
       " '(c) 3.5 x 105 ppm',\n",
       " '(d) 35.0 ppm',\n",
       " '',\n",
       " 'ii) You fill a balloon up with He in Palo Alto, where the pressure is 0.96 atm, and then drive with',\n",
       " \"your balloon to your cousin's birthday party in Denver, where the pressure is 0.81 atm. If the\",\n",
       " 'volume of the balloon in Palo Alto is 2.7 L, what will be the volume of the balloon in Denver?',\n",
       " 'Assume that no He escapes from the balloon during the road trip and that the temperature in',\n",
       " 'Palo Alto and Denver are the same.',\n",
       " '(a) 1.2 L',\n",
       " '(b) 2.7 L',\n",
       " '(c) 3.2 L',\n",
       " '(d) 2.3 L',\n",
       " '(e) Not enough information to say.',\n",
       " '',\n",
       " 'iii) Household bleach is typically sold at a concentration of 1.11 M NaOCl (aqueous), but for',\n",
       " 'disinfection it is recommended to use a solution of 23.1 mM sodium hypochlorite (aqueous).',\n",
       " 'What is the maximum volume of disinfecting solution you can prepare from a 3.79 L bottle',\n",
       " 'of household bleach purchased from the store?',\n",
       " '(a) 182 L',\n",
       " '(b) 15.6 L',\n",
       " '(c) 37.9 L',\n",
       " '(d) 111 L',\n",
       " '(e) Not enough information to say',\n",
       " '',\n",
       " 'iv) Different ions of the same element differ in the number of:',\n",
       " '(a) electrons.',\n",
       " '(b) neutrons.',\n",
       " '(c) protons.',\n",
       " '(d) neutrons and protons.',\n",
       " '(e) electrons and protons.',\n",
       " '',\n",
       " 'v) How many electrons does the Ba2+ ion possess?',\n",
       " '(a) 56',\n",
       " '(b) 58',\n",
       " '(c) 54',\n",
       " '(d) 55',\n",
       " '(e) 88',\n",
       " '',\n",
       " '2) Short Answer [40 points]',\n",
       " 'a) Suppose Elon Musk drives from Los Angeles to San Francisco',\n",
       " '(382 miles) in a 2021 Tesla Model 3, which has standard-range',\n",
       " 'battery with a rating of 24.0 kWh/100 miles. If he charges his car',\n",
       " 'on the California grid, where 48.35% of electricity is generated',\n",
       " 'from natural gas, 0.170% from coal, 0.0200% from oil, and the',\n",
       " 'rest from renewable energy (assume no CO2 is emitted from',\n",
       " 'renewable energy), how many kilograms of CO2 were emitted to',\n",
       " 'generate the electricity required for his trip? (See Table below)',\n",
       " '',\n",
       " 'b) We saw in lab that the reaction of acetic acid with sodium',\n",
       " 'bicarbonate produces water, carbon dioxide, and sodium acetate',\n",
       " '(see balanced equation below). You add 95 mL of a 0.933 molar',\n",
       " '(M) aqueous solution of acetic acid (molar mass: 60.05 g/mol)',\n",
       " 'containing red cabbage pH indicator to an open beaker and',\n",
       " 'record the total mass as 275 g. You then add 5.0 g of sodium',\n",
       " 'bicarbonate (molar mass: 84.0 g/mol) to the jar, stir, and wait for',\n",
       " 'the reaction to finish. After the reaction is complete, you weigh the jar again. Assume the mass of pH indicator is negligible (it doesnt contribute anything to the overall mass).',\n",
       " '',\n",
       " 'i.) What color is the liquid in the beaker after the reaction is complete? Justify your answer with a',\n",
       " 'calculation.',\n",
       " '',\n",
       " 'ii.) When you weigh the jar after the reaction, do you expect the mass to be about equal to 280g, less than 280g or more than 280g? Briefly explain your answer.',\n",
       " '',\n",
       " 'c) Aqueous lead nitrate reacts with potassium iodide to form solid lead iodide as a precipitate. The',\n",
       " 'balanced molecular equation is shown below. If 1.54 g of potassium iodide reacts completely with',\n",
       " 'excess lead nitrate in an aqueous solution to form 1.46 g of lead iodide precipitate, what is the percent',\n",
       " 'yield of the reaction?',\n",
       " 'Molar Mass (Pb(NO3)2): 331.2 g/mol; (KI): 166.0 g/mol; (PbI2): 461.0 g/mol; (KNO3): 101.1 g/mol',\n",
       " '',\n",
       " 'Pb(NO3)2 (aq) + 2KI (aq) \\xa0 PbI2 (s) + 2KNO3 (aq)',\n",
       " '',\n",
       " '3) [35 points] You obtain a small sample of an unknown compound extracted from the bark of a South',\n",
       " 'American tree. The indigenous people used powders of this bark to treat shivering. To identify this',\n",
       " 'compound, the following experiments were carried out.',\n",
       " 'Exp. #1: 25.10 mg of a sample of the pure compound was combusted to yield 18.58 mg carbon',\n",
       " 'Exp. #2: 25.10 mg of a sample of the pure compound was analyzed to yield 2.167 mg nitrogen',\n",
       " 'Exp. #3: 25.10 mg of a sample of the pure compound was combusted to yield 1.872 mg',\n",
       " 'hydrogen',\n",
       " 'Exp. #4: X-ray photoelectron spectroscopy (well learn this technique later) indicated the pure',\n",
       " 'compound contained only the following elements: C, H, N, O.',\n",
       " 'Exp. #5: A low resolution mass spectrum of the pure compound yield an ion corresponding to',\n",
       " 'the mass 324 amu.',\n",
       " 'a) Assuming you dont know anything about this compound already, which experiment(s) are',\n",
       " 'both sufficient and necessary to allow you to determine the empirical formula of this',\n",
       " 'compound (circle all that apply).',\n",
       " '1 2 3 4 5',\n",
       " 'b) Assuming you dont know anything about this compound already, which experiment(s) are',\n",
       " 'both sufficient and necessary to allow you to determine the molecular formula of this',\n",
       " 'compound (circle all that apply).',\n",
       " '1 2 3 4 5',\n",
       " 'c) Determine the empirical formula of this compound',\n",
       " '',\n",
       " '4) [35 points]. 95.3 g of FeS2 and 54.0 L of O2 are sealed in a sealed 54.0 L container at 398 K and 1.20atm. These two react to generate Fe2O3 and sulfur dioxide. The molar mass of FeS2 is 119.99 g/mol',\n",
       " 'and that of Fe2O3(s) is 159.687 g/mol.',\n",
       " '4 FeS2(s) + 11 O2(g)  2 Fe2O3(s) + 8 SO2(g)',\n",
       " 'a) How many grams of Fe2O3(s) would be generated?',\n",
       " '',\n",
       " 'b) What would be the final pressure in the sealed 54.0L container if, at the end of the reaction, the',\n",
       " 'container was held at 25C?',\n",
       " '',\n",
       " '5) [35 points]. Hydrogen Fluoride is a highly toxic molecule used in many industrial chemical',\n",
       " 'processes. It can also be dissolved in water to form hydrofluoric acid. Exposure to hydrogen fluoride',\n",
       " 'or hydrofluoric acid can not only cause tissue damage but can also cause systemic problems since',\n",
       " 'fluoride precipitates calcium out of solution, and a significant decrease in the concentration of',\n",
       " 'calcium ions in the blood can cause cardiac arrest and death.',\n",
       " 'a) Write the chemical formulas for hydrogen fluoride and calcium fluoride',\n",
       " '',\n",
       " 'b) Write the balanced net ionic equation for the precipitation of calcium fluoride from fluoride',\n",
       " 'and calcium ions in your blood (an aqueous solution) - Dont forget to indicate states of matter!',\n",
       " '',\n",
       " 'c) A common treatment for skin exposure to hydrofluoric acid is to apply a gel containing',\n",
       " 'calcium gluconate to the site of exposure as soon as possible. Calcium gluconate is a calcium',\n",
       " 'salt that is soluble in water, where it dissolves into calcium and gluconate ions. In one or two',\n",
       " 'sentences, describe how calcium gluconate likely works to treat hydrofluoric acid exposure.',\n",
       " 'The molecular formula of calcium gluconate is Ca(C6H11O7)2.',\n",
       " '',\n",
       " 'd) Calcium gluconate gel is usually provided at a concentration of 2.5% calcium gluconate by',\n",
       " 'mass. If you spill 5.00 mL of a 28.9 mM aqueous solution of hydrogen fluoride on your arm,',\n",
       " 'what is the minimum mass of calcium gluconate gel you should apply to your arm to',\n",
       " 'precipitate all the fluoride? The molar mass of calcium gluconate is 430.37 g/mol.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('learning_goal_list.txt', encoding='utf-8') as f:\n",
    "    learning_goals = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1267"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learning_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('question_list.json') as f:\n",
    "    questions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4875"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "OPENSTAX_COURSES = [\n",
    "    'Chemistry 2e', \n",
    "    'University Physics Volume 1', \n",
    "    'University Physics Volume 2', \n",
    "    'University Physics Volume 3'\n",
    "]\n",
    "\n",
    "PRINCIPLES_OF_CHEMISTRY_COURSE = 'Principles of Chemistry 3rd edition'\n",
    "\n",
    "data = pd.concat([\n",
    "    util.load_openstax_course(course) for course in OPENSTAX_COURSES\n",
    "] + [util.load_principles_of_chemistry_course(PRINCIPLES_OF_CHEMISTRY_COURSE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4875, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('question').agg(list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(util.load_chem31a_course()['learning_goal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4875, 4096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.load('question_curie_embeddings.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Write a nuclear equation for the indicated decay of each\\nnuclide.\\na. Po-210 (alpha) b. Ac-227 (beta)\\nc. Tl-207 (beta) d. O-15 (positron emission)\\ne. Pd-103 (electron capture)'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data[data['course'] == 'Principles of Chemistry 3rd edition'].sample()\n",
    "s['question'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Writing Nuclear Equations for Alpha Decay',\n",
       "       'Writing Nuclear Equations for Beta Decay, Positron Emission, and Electron Capture'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['question'] == s.iloc[0]['question']]['learning_goal'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('learning_goal').agg(list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "question_embeddings = torch.load('question_curie_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_goals = torch.load('learning_goal_curie_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(data.groupby('learning_goal').agg(list).index, learning_goals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(questions, question_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[list(d.keys())[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict(task):\n",
    "    predictions_batch = []\n",
    "    support, labels_support, query, labels_query = task\n",
    "\n",
    "    n = 2\n",
    "    k = labels_support.shape[0] // n\n",
    "\n",
    "    # (n, dim)\n",
    "    prototypes = support.view(n, k, -1).mean(dim=1)\n",
    "\n",
    "    # (nq, n) \n",
    "    # query_distances = torch.cdist(query, prototypes) \n",
    "    query_distances = torch.tensor([\n",
    "        [F.cosine_similarity(p, q, dim=0) for p in prototypes]\n",
    "        for q in query\n",
    "    ])\n",
    "    query_logits = F.softmax(query_distances, dim=1)\n",
    "\n",
    "    # return torch.argmax(query_logits, dim=-1)\n",
    "    return query_logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "from openstax_dataset import GPT3Dataset\n",
    "\n",
    "dataset = GPT3Dataset(\n",
    "    num_support=5,\n",
    "    num_query=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for task in dataset:\n",
    "    preds.append(predict(task))\n",
    "    labels.append(task[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(961, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = np.stack(preds)[:, :, 1]\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True, False],\n",
       "       ...,\n",
       "       [False, False],\n",
       "       [ True,  True],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(961, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.stack(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5244536940686785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score \n",
    "\n",
    "accuracy_score(y_true=labels.flatten(), y_pred=(predictions >= 0.5).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5404630755554016"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true=labels.flatten(), y_score=predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5413780190990843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_true=labels.flatten(), y_score=predictions.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "OPENAI_API_TOKEN = '<>'\n",
    "openai.api_key = OPENAI_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "\n",
    "df = util.load_chem31a_course()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "# questions = df.groupby('question').agg(list).index\n",
    "learning_goals = df.groupby('learning_goal').agg(list).index\n",
    "for lg in learning_goals:\n",
    "    response = openai.Embedding.create(\n",
    "        input=lg,\n",
    "        model=\"text-similarity-curie-001\"\n",
    "    )\n",
    "    embeddings.append(response['data'][0]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embs = torch.tensor(embeddings)\n",
    "\n",
    "# torch.save(embs, 'learning_goal_curie_embeddings_chem31a.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([98, 4096])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('question_curie_embeddings_chem31a.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openstax_dataset import GPT3TestDataset\n",
    "\n",
    "test_dataset = GPT3TestDataset(\n",
    "    course_name='Chem 31A',\n",
    "    num_support=5,\n",
    "    num_query=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for d in test_dataset:\n",
    "    for task in d:\n",
    "        preds.append(predict(task)[0][1])\n",
    "        labels.append(task[-1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3528"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.array(preds).reshape(-1, len(d))\n",
    "labels = np.array(labels).reshape(-1, len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import pandas as pd\n",
    "\n",
    "data = util.load_chem31a_course()\n",
    "\n",
    "questions = data.groupby('question').agg(list).index\n",
    "learning_goals = data.groupby('learning_goal').agg(list)\n",
    "learning_goals = learning_goals[learning_goals['question'].apply(len) > 1].index\n",
    "\n",
    "true_data = pd.DataFrame(labels, index=questions, columns=learning_goals)\n",
    "pred_data = pd.DataFrame(preds, index=questions, columns=learning_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At 25o C, a gas with a molecular weight of 44g/mol is contained in a vessel under very high-pressure conditions and has an initial density of 0.44 g/mL. The vessel is sealed by a movablepiston of radius 5.0 cm. Assuming the gas still behaves ideally, what is the magnitude of theforce (in Newtons) exerted by the gas on the piston?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "true_data.iloc[index].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Use the ideal gas law (PV=nRT) to solve problems.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_lgs = [c for c in true_data.columns if true_data.iloc[index][c]]\n",
    "true_lgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.51482064, 'Use the ideal gas law (PV=nRT) to solve problems.'),\n",
       " (0.5082098, 'Know the difference between systems and surroundings'),\n",
       " (0.5053514,\n",
       "  'Predict how any two independent variables of a gas (P, V, n, R, T) change if the others are held constant.'),\n",
       " (0.50470126,\n",
       "  'Relate average kinetic energy to temperature, calculate root mean squared (RMS) velocity'),\n",
       " (0.5044674,\n",
       "  'Apply the concept of percent by mass and percent by volume when solving problems.'),\n",
       " (0.50393236,\n",
       "  'Use gas laws with stoichiometry to analyze chemical reactions of gasses'),\n",
       " (0.50231206, 'Apply dimensional analysis to guide problem solving'),\n",
       " (0.5019876, 'Calculate the work done by or on a gas.'),\n",
       " (0.5011426,\n",
       "  'Sketch the distributions of velocity, speed, and kinetic energy as predicted by the Maxwell Boltzmann distribution'),\n",
       " (0.5009379,\n",
       "  'Calculate changes in energy, enthalpy, and temperature that result from a chemical reaction.'),\n",
       " (0.5006031,\n",
       "  'Know how to name ionic and covalent compounds for main group and transition metal elements.'),\n",
       " (0.5003435, 'Identify when a limiting reagent calculation is necessary.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_lgs = sorted([(pred_data.iloc[index][c], c) for c in pred_data.columns if (pred_data.iloc[index][c] >= 0.5)], reverse=True)\n",
    "pred_lgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8511904761904762"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_pred=(preds >= 0.5).flatten(), y_true=labels.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6939727270916802"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_score=preds, y_true=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3299534998478556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "average_precision_score(y_score=preds, y_true=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "X, y = make_multilabel_classification(random_state=0)\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf = MultiOutputClassifier(clf).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict_proba(X)\n",
    "y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82664884, 0.86034414, 0.94181818, 0.8502652 , 0.94809095])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train GPT-3 Based NN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ShallowNN(nn.Module):\n",
    "    def __init__(self, input_size) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size * 2, input_size * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_size * 2, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        return self.model(torch.cat([x, y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't have question 17 from chapter 1\n",
      "We don't have question 18 from chapter 1\n",
      "We don't have question 31 from chapter 2\n",
      "We don't have question 32 from chapter 2\n",
      "We don't have question 4 from chapter 13\n",
      "We don't have question 5 from chapter 13\n",
      "We don't have question 6 from chapter 13\n",
      "We don't have question 19 from chapter 15\n",
      "We don't have question 20 from chapter 15\n"
     ]
    }
   ],
   "source": [
    "from openstax_dataset import GPT3Dataset\n",
    "\n",
    "dataset = GPT3Dataset(\n",
    "    num_support=5,\n",
    "    num_query=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_SIZE = 4096\n",
    "dist_model = ShallowNN(EMB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(task, device):\n",
    "    support, labels_support, query, labels_query = task\n",
    "\n",
    "    support = support.to(device)\n",
    "    query = query.to(device)\n",
    "    labels_query = labels_query.to(device)\n",
    "\n",
    "    n = 2\n",
    "    k = support.size(0) // n\n",
    "\n",
    "    prototypes = support.view(n, k, -1).mean(dim=1)\n",
    "\n",
    "    distances = torch.stack([\n",
    "        dist_model(p, q) for q in query for p in prototypes\n",
    "    ]).view(labels_query.size(0), n)\n",
    "\n",
    "    query_logits = F.softmax(-distances, dim=-1)\n",
    "\n",
    "    loss = F.cross_entropy(query_logits, labels_query)\n",
    "    accuracy_query = util.score(query_logits, labels_query)\n",
    "\n",
    "    return loss, accuracy_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, num_epochs, device, lr=1e-5):\n",
    "    dist_model.to(device)\n",
    "    dist_model.train()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        dist_model.parameters(),\n",
    "        lr=lr\n",
    "    )\n",
    "    optimizer.zero_grad()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for task in dataset:\n",
    "            loss, accuracy = step(task, device)\n",
    "            accuracies.append(accuracy)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        print('Epoch', epoch)\n",
    "        print('Accuracy', np.mean(accuracies))\n",
    "        print('Loss', np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 4.00 GiB total capacity; 1.00 GiB already allocated; 105.70 MiB free; 1.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [426], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m train(dataset, \u001b[39m1\u001b[39;49m, device)\n",
      "Cell \u001b[1;32mIn [425], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, num_epochs, device, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m     accuracies\u001b[39m.\u001b[39mappend(accuracy)\n\u001b[0;32m     15\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m---> 17\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch\u001b[39m\u001b[39m'\u001b[39m, epoch)\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\cs330\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\amirz\\.conda\\envs\\cs330\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 4.00 GiB total capacity; 1.00 GiB already allocated; 105.70 MiB free; 1.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "train(dataset, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "59e0f2f90842c596b98da9224b23f809feee7517a6cc086421584e6ea1d0387b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
